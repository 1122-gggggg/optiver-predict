{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa3251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>is_far_price_missing</th>\n",
       "      <th>is_near_price_missing</th>\n",
       "      <th>is_wap_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64   1.004805   \n",
       "1                       -1         0.999896    1642214.25   1.004805   \n",
       "2                       -1         0.999561    1819368.03   1.004805   \n",
       "3                       -1         1.000171   18389745.62   1.004805   \n",
       "4                       -1         0.999532   17860614.95   1.004805   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0    0.999735   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1    0.999735   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2    0.999735   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3    0.999735   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4    0.999735   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id  is_far_price_missing  is_near_price_missing  is_wap_missing  \n",
       "0        0                     1                      1               0  \n",
       "1        0                     1                      1               0  \n",
       "2        0                     1                      1               0  \n",
       "3        0                     1                      1               0  \n",
       "4        0                     1                      1               0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train = train.drop('row_id', axis=1)\n",
    "\n",
    "train['is_far_price_missing'] = train['far_price'].isnull().astype(int)\n",
    "train['is_near_price_missing'] = train['near_price'].isnull().astype(int)\n",
    "train['is_wap_missing'] = train['wap'].isnull().astype(int)\n",
    "\n",
    "columns_to_fill = ['imbalance_size', 'reference_price', 'matched_size', \n",
    "                   'bid_price', 'ask_price', 'wap','far_price','near_price', 'target']\n",
    "\n",
    "for column in columns_to_fill:\n",
    "    train[column].fillna(train[column].mean(), inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060cbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsi(data, window=14):\n",
    "    # Calculate daily price changes\n",
    "    delta = data.diff()\n",
    "\n",
    "    # Separate the gains and losses\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "\n",
    "    # Calculate the average gains and losses over the specified window\n",
    "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate the Relative Strength (RS)\n",
    "    rs = avg_gain / avg_loss\n",
    "\n",
    "    # Calculate the Relative Strength Index (RSI)\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    return rsi\n",
    "\n",
    "def calculate_fibonacci_retracement(high, low):\n",
    "    diff = high - low\n",
    "    level1 = high - 0.236 * diff\n",
    "    level2 = high - 0.382 * diff\n",
    "    level3 = high - 0.618 * diff\n",
    "    return level1, level2, level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76854afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>price_spread</th>\n",
       "      <th>price_pressure</th>\n",
       "      <th>market_urgency</th>\n",
       "      <th>cumsum_buy_imbalance</th>\n",
       "      <th>cumsum_sell_imbalance</th>\n",
       "      <th>order_flow_imbalance</th>\n",
       "      <th>volume_price_interaction</th>\n",
       "      <th>wap_lagged</th>\n",
       "      <th>price_shock</th>\n",
       "      <th>volume_shock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>680.648976</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>7.919304e+07</td>\n",
       "      <td>52158.47</td>\n",
       "      <td>69144.510249</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>127.285387</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>7.557098e+07</td>\n",
       "      <td>1.666039e+05</td>\n",
       "      <td>-17372.05</td>\n",
       "      <td>23838.120877</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>271.077484</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>7.557098e+07</td>\n",
       "      <td>4.694838e+05</td>\n",
       "      <td>18961.00</td>\n",
       "      <td>56950.970873</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>2562.301688</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>7.557098e+07</td>\n",
       "      <td>1.238717e+07</td>\n",
       "      <td>-476707.50</td>\n",
       "      <td>481357.318496</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.004805</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>278.376075</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>7.557098e+07</td>\n",
       "      <td>1.283472e+07</td>\n",
       "      <td>16051.44</td>\n",
       "      <td>16919.640704</td>\n",
       "      <td>1.000059</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64   1.004805   \n",
       "1                       -1         0.999896    1642214.25   1.004805   \n",
       "2                       -1         0.999561    1819368.03   1.004805   \n",
       "3                       -1         1.000171   18389745.62   1.004805   \n",
       "4                       -1         0.999532   17860614.95   1.004805   \n",
       "\n",
       "   near_price  bid_price  ...  price_spread  price_pressure  market_urgency  \\\n",
       "0    0.999735   0.999812  ...      0.000214      680.648976        0.000161   \n",
       "1    0.999735   0.999896  ...      0.000764      127.285387       -0.000557   \n",
       "2    0.999735   0.999403  ...      0.000895      271.077484        0.000298   \n",
       "3    0.999735   0.999999  ...      0.000215     2562.301688       -0.000213   \n",
       "4    0.999735   0.999394  ...      0.000622      278.376075        0.000590   \n",
       "\n",
       "   cumsum_buy_imbalance  cumsum_sell_imbalance  order_flow_imbalance  \\\n",
       "0          3.180603e+06           7.919304e+07              52158.47   \n",
       "1          7.557098e+07           1.666039e+05             -17372.05   \n",
       "2          7.557098e+07           4.694838e+05              18961.00   \n",
       "3          7.557098e+07           1.238717e+07            -476707.50   \n",
       "4          7.557098e+07           1.283472e+07              16051.44   \n",
       "\n",
       "   volume_price_interaction  wap_lagged  price_shock  volume_shock  \n",
       "0              69144.510249    1.000059        False         False  \n",
       "1              23838.120877    1.000059        False         False  \n",
       "2              56950.970873    1.000059        False         False  \n",
       "3             481357.318496    1.000059         True         False  \n",
       "4              16919.640704    1.000059        False          True  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train['high'] = train.groupby('stock_id')['wap'].rolling(window=20,min_periods=1).max().reset_index(level=0, drop=True)\n",
    "train['low'] = train.groupby('stock_id')['wap'].rolling(window=20,min_periods=1).min().reset_index(level=0, drop=True)\n",
    "\n",
    "#fibonacci\n",
    "train['fib_level_1'], train['fib_level_2'], train['fib_level_3'] = zip(*train.apply(lambda row: calculate_fibonacci_retracement(row['high'], row['low']), axis=1))\n",
    "train['support'] = train['low'].rolling(window=20, min_periods=1).min()\n",
    "train['resistance'] = train['high'].rolling(window=20, min_periods=1).max()\n",
    "\n",
    "# Feature lists for price and size\n",
    "price_ftrs = ['reference_price', 'bid_price', 'ask_price', 'wap']\n",
    "size_ftrs = ['imbalance_size', 'matched_size', 'bid_size', 'ask_size']\n",
    "\n",
    "# Rolled sum for size features\n",
    "rolled = train[['stock_id'] + size_ftrs].groupby('stock_id').rolling(window=6, min_periods=1).sum()\n",
    "rolled = rolled.reset_index(level=0, drop=True)\n",
    "for col in size_ftrs:\n",
    "    train[f'{col}_rolled_sum'] = rolled[col]\n",
    "\n",
    "# Rolled standard deviation for price features\n",
    "rolled = train[['stock_id'] + price_ftrs].groupby('stock_id').rolling(window=6, min_periods=1).std().fillna(0)\n",
    "rolled = rolled.reset_index(level=0, drop=True)\n",
    "for col in price_ftrs:\n",
    "    train[f'{col}_rolled_std'] = rolled[col]\n",
    "\n",
    "# Weighted average price (wap)\n",
    "train['wap'] = (train['bid_price'] * train['ask_size'] + train['ask_price'] * train['bid_size']) / (train['bid_size'] + train['ask_size'])\n",
    "\n",
    "# Time decayed WAP\n",
    "train['wap_time_decay'] = train.groupby('stock_id')['wap'].transform(lambda x: x.ewm(halflife=3).mean())\n",
    "\n",
    "# Moving averages\n",
    "# 為滾動計算指定 min_periods\n",
    "train['moving_avg_5'] = train['wap'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "train['moving_avg_10'] = train['wap'].rolling(window=10,min_periods=1).mean()\n",
    "train['ewma_10'] = train['wap'].ewm(span=10, adjust=False).mean()\n",
    "train['volatility_10'] = train['wap'].rolling(window=10,min_periods=1).std()\n",
    "# Different window sizes for rolling averages and adjusted exponential weights\n",
    "train['moving_avg_20'] = train['wap'].rolling(window=20,min_periods=1).mean()\n",
    "train['ewma_20'] = train['wap'].ewm(span=20, adjust=False).mean()\n",
    "# MACD (Moving Average Convergence Divergence)\n",
    "train['macd'] = train['moving_avg_5'] - train['moving_avg_10']\n",
    "\n",
    "# Rolling measures\n",
    "train['rolling_std'] = train['wap'].rolling(window=20,min_periods=1).std()\n",
    "train['rolling_corr'] = train['wap'].rolling(window=20,min_periods=1).corr(train['moving_avg_10'])\n",
    "# 使用 fillna 填充 NaN 值\n",
    "train['rolling_std'] = train['wap'].rolling(window=20, min_periods=1).std().fillna(0)\n",
    "\n",
    "# Relative Strength Index (RSI)\n",
    "train['rsi_14'] = compute_rsi(train['wap'])\n",
    "\n",
    "# Skewness and Kurtosis\n",
    "train['wap_skewness'] = train.groupby('stock_id')['wap'].rolling(window=20,min_periods=1).skew().reset_index(level=0, drop=True)\n",
    "train['wap_kurtosis'] = train.groupby('stock_id')['wap'].rolling(window=20,min_periods=1).kurt().reset_index(level=0, drop=True)\n",
    "\n",
    "# Volatility Clustering\n",
    "train['volatility_clustering'] = train['volatility_10'] * train['volatility_10'].shift(1)\n",
    "\n",
    "# Imbalance and liquidity features\n",
    "train['imb_s1'] = (train['bid_size'] - train['ask_size']) / (train['bid_size'] + train['ask_size'])\n",
    "train['imb_s2'] = (train['imbalance_size'] - train['matched_size']) / (train['matched_size'] + train['imbalance_size'])\n",
    "train[\"volume\"] = train[\"ask_size\"] + train[\"bid_size\"]\n",
    "train[\"mid_price\"] = (train[\"ask_price\"] + train[\"bid_price\"]) / 2\n",
    "train[\"liquidity_imbalance\"] = (train[\"bid_size\"] - train[\"ask_size\"]) / (train[\"bid_size\"] + train[\"ask_size\"])\n",
    "train[\"matched_imbalance\"] = (train[\"imbalance_size\"] - train[\"matched_size\"]) / (train[\"matched_size\"] + train[\"imbalance_size\"])\n",
    "train[\"all_size\"] = train[\"matched_size\"] + train[\"imbalance_size\"]\n",
    "train[\"imbalance_size_for_buy_sell\"] = train[\"imbalance_size\"] * train[\"imbalance_buy_sell_flag\"]\n",
    "train[\"price_spread\"] = train[\"ask_price\"] - train[\"bid_price\"]\n",
    "train['price_pressure'] = train['imbalance_size'] * (train['ask_price'] - train['bid_price'])\n",
    "train['market_urgency'] = train['price_spread'] * train['liquidity_imbalance']\n",
    "\n",
    "# Cumulative sum of buy and sell imbalances\n",
    "train['cumsum_buy_imbalance'] = train[train['imbalance_buy_sell_flag'] == 1]['imbalance_size'].rolling(window=10,min_periods=1).sum().fillna(0)\n",
    "train['cumsum_sell_imbalance'] = train[train['imbalance_buy_sell_flag'] == -1]['imbalance_size'].rolling(window=10,min_periods=1).sum().fillna(0)\n",
    "\n",
    "# Order flow imbalance\n",
    "train['order_flow_imbalance'] = train['bid_size'] - train['ask_size']\n",
    "\n",
    "# Interaction between volume and price\n",
    "train['volume_price_interaction'] = train['volume'] * train['wap']\n",
    "\n",
    "# Lagged features\n",
    "train['wap_lagged'] = train.groupby('stock_id')['wap'].shift(1)\n",
    "\n",
    "# Price and volume shocks\n",
    "train['price_shock'] = (train['wap'] - train['wap'].shift(1)).abs() > train['wap'].rolling(window=20,min_periods=1).std() * 2\n",
    "train['volume_shock'] = (train['volume'] - train['volume'].shift(1)).abs() > train['volume'].rolling(window=20,min_periods=1).std() * 2\n",
    "\n",
    "features = [\n",
    "    'wap', 'volatility_10', 'rolling_corr', 'rsi_14', 'wap_skewness', \n",
    "    'wap_kurtosis', 'volatility_clustering', 'imb_s1', 'liquidity_imbalance', \n",
    "    'market_urgency', 'cumsum_buy_imbalance', 'cumsum_sell_imbalance', \n",
    "    'volume_price_interaction', 'wap_lagged'\n",
    "]\n",
    "\n",
    "for feature in features:\n",
    "    train[feature].fillna(train[feature].mean(), inplace=True)\n",
    "    \n",
    "nan_columns = train.columns[train.isna().any()].tolist()\n",
    "nan_columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6202064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date_id into cyclical features\n",
    "train['date_sin'] = np.sin((train['date_id'] / train['date_id'].max()) * 2 * np.pi)\n",
    "train['date_cos'] = np.cos((train['date_id'] / train['date_id'].max()) * 2 * np.pi)\n",
    "\n",
    "# Transform seconds_in_bucket into cyclical features\n",
    "max_seconds = train['seconds_in_bucket'].max()\n",
    "train['seconds_sin'] = np.sin((train['seconds_in_bucket'] / max_seconds) * 2 * np.pi)\n",
    "train['seconds_cos'] = np.cos((train['seconds_in_bucket'] / max_seconds) * 2 * np.pi)\n",
    "\n",
    "# Drop the original columns if they are no longer needed\n",
    "train = train.drop(['date_id', 'seconds_in_bucket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da710db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\90607\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\90607\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\90607\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " stock_id_input (InputLayer  [(None, 1)]               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1, 10)             2000      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1408      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13777 (53.82 KB)\n",
      "Trainable params: 13777 (53.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "max_stock_id = int(train['stock_id'].max()) + 1 \n",
    "embedding_dim_stock_id = 10  \n",
    "stock_id_input = Input(shape=(1,), name='stock_id_input')\n",
    "stock_id_embed = Embedding(max_stock_id, embedding_dim_stock_id, input_length=1)(stock_id_input)\n",
    "stock_id_embed = Flatten()(stock_id_embed)\n",
    "\n",
    "hidden_1 = Dense(128, activation='relu')(stock_id_embed)\n",
    "hidden_1 = Dropout(0.3)(hidden_1)  \n",
    "hidden_2 = Dense(64, activation='relu')(hidden_1)\n",
    "hidden_2 = Dropout(0.3)(hidden_2)  \n",
    "hidden_3 = Dense(32, activation='relu')(hidden_2)\n",
    "output = Dense(1, activation='linear')(hidden_3)\n",
    "\n",
    "model = Model(inputs=stock_id_input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>...</th>\n",
       "      <th>cumsum_sell_imbalance</th>\n",
       "      <th>order_flow_imbalance</th>\n",
       "      <th>volume_price_interaction</th>\n",
       "      <th>wap_lagged</th>\n",
       "      <th>price_shock</th>\n",
       "      <th>volume_shock</th>\n",
       "      <th>date_sin</th>\n",
       "      <th>date_cos</th>\n",
       "      <th>seconds_sin</th>\n",
       "      <th>seconds_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.121738</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115157</td>\n",
       "      <td>-0.205215</td>\n",
       "      <td>8.659673e-16</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>-0.001214</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.668587e-16</td>\n",
       "      <td>0.306005</td>\n",
       "      <td>-0.188227</td>\n",
       "      <td>-1.029758e-13</td>\n",
       "      <td>-0.430627</td>\n",
       "      <td>-0.422469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.266311</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.076658</td>\n",
       "      <td>-0.278663</td>\n",
       "      <td>8.659673e-16</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0.037813</td>\n",
       "      <td>-0.399984</td>\n",
       "      <td>0.160209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.415251e+00</td>\n",
       "      <td>-0.076036</td>\n",
       "      <td>-0.399290</td>\n",
       "      <td>-1.029758e-13</td>\n",
       "      <td>-0.430627</td>\n",
       "      <td>-0.422469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.259774</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.230194</td>\n",
       "      <td>-0.277554</td>\n",
       "      <td>8.659673e-16</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>-0.191240</td>\n",
       "      <td>-0.120927</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.409827e+00</td>\n",
       "      <td>0.123599</td>\n",
       "      <td>-0.245032</td>\n",
       "      <td>-1.029758e-13</td>\n",
       "      <td>-0.430627</td>\n",
       "      <td>-0.422469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.297354</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.049379</td>\n",
       "      <td>-0.173869</td>\n",
       "      <td>8.659673e-16</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0.085668</td>\n",
       "      <td>-0.407283</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.196399e+00</td>\n",
       "      <td>-2.599885</td>\n",
       "      <td>1.732091</td>\n",
       "      <td>-1.029758e-13</td>\n",
       "      <td>2.322193</td>\n",
       "      <td>-0.422469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.252835</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.243486</td>\n",
       "      <td>-0.177180</td>\n",
       "      <td>8.659673e-16</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>-0.195421</td>\n",
       "      <td>-0.293478</td>\n",
       "      <td>-0.136760</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.188384e+00</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>-0.431520</td>\n",
       "      <td>-1.029758e-13</td>\n",
       "      <td>-0.430627</td>\n",
       "      <td>2.367038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  imbalance_size  imbalance_buy_sell_flag  reference_price  \\\n",
       "0         0       -0.121738                        1        -0.115157   \n",
       "1         1       -0.266311                       -1        -0.076658   \n",
       "2         2       -0.259774                       -1        -0.230194   \n",
       "3         3        0.297354                       -1         0.049379   \n",
       "4         4       -0.252835                       -1        -0.243486   \n",
       "\n",
       "   matched_size     far_price    near_price  bid_price  bid_size  ask_price  \\\n",
       "0     -0.205215  8.659673e-16  1.709458e-14  -0.001214  0.061469  -0.132149   \n",
       "1     -0.278663  8.659673e-16  1.709458e-14   0.037813 -0.399984   0.160209   \n",
       "2     -0.277554  8.659673e-16  1.709458e-14  -0.191240 -0.120927  -0.006721   \n",
       "3     -0.173869  8.659673e-16  1.709458e-14   0.085668 -0.407283  -0.045456   \n",
       "4     -0.177180  8.659673e-16  1.709458e-14  -0.195421 -0.293478  -0.136760   \n",
       "\n",
       "   ...  cumsum_sell_imbalance  order_flow_imbalance  volume_price_interaction  \\\n",
       "0  ...          -2.668587e-16              0.306005                 -0.188227   \n",
       "1  ...          -1.415251e+00             -0.076036                 -0.399290   \n",
       "2  ...          -1.409827e+00              0.123599                 -0.245032   \n",
       "3  ...          -1.196399e+00             -2.599885                  1.732091   \n",
       "4  ...          -1.188384e+00              0.107612                 -0.431520   \n",
       "\n",
       "     wap_lagged  price_shock  volume_shock  date_sin  date_cos  seconds_sin  \\\n",
       "0 -1.029758e-13    -0.430627     -0.422469       0.0       1.0          0.0   \n",
       "1 -1.029758e-13    -0.430627     -0.422469       0.0       1.0          0.0   \n",
       "2 -1.029758e-13    -0.430627     -0.422469       0.0       1.0          0.0   \n",
       "3 -1.029758e-13     2.322193     -0.422469       0.0       1.0          0.0   \n",
       "4 -1.029758e-13    -0.430627      2.367038       0.0       1.0          0.0   \n",
       "\n",
       "   seconds_cos  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_scale = [\n",
    "    'support','resistance',\n",
    "    'imbalance_size', 'reference_price', 'matched_size', 'far_price', \n",
    "    'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap',\n",
    "    'imbalance_size_rolled_sum', 'matched_size_rolled_sum', \n",
    "    'bid_size_rolled_sum', 'ask_size_rolled_sum', 'reference_price_rolled_std',\n",
    "    'bid_price_rolled_std', 'ask_price_rolled_std', 'wap_rolled_std',\n",
    "    'wap_time_decay', 'moving_avg_5', 'moving_avg_10', 'ewma_10', \n",
    "    'volatility_10', 'moving_avg_20', 'ewma_20', 'macd', 'rolling_std', \n",
    "    'rolling_corr', 'rsi_14', 'wap_skewness', 'wap_kurtosis', \n",
    "    'volatility_clustering', 'volume', 'mid_price', 'liquidity_imbalance', \n",
    "    'matched_imbalance', 'all_size', 'imbalance_size_for_buy_sell', \n",
    "    'price_spread', 'price_pressure', 'market_urgency', 'cumsum_buy_imbalance',\n",
    "    'cumsum_sell_imbalance', 'order_flow_imbalance', 'volume_price_interaction', \n",
    "    'wap_lagged', 'price_shock', 'volume_shock'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train[features_to_scale] = scaler.fit_transform(train[features_to_scale])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2930d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
       "       'reference_price', 'matched_size', 'far_price', 'near_price',\n",
       "       'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target',\n",
       "       'time_id', 'is_far_price_missing', 'is_near_price_missing',\n",
       "       'is_wap_missing', 'high', 'low', 'fib_level_1', 'fib_level_2',\n",
       "       'fib_level_3', 'support', 'resistance', 'imbalance_size_rolled_sum',\n",
       "       'matched_size_rolled_sum', 'bid_size_rolled_sum', 'ask_size_rolled_sum',\n",
       "       'reference_price_rolled_std', 'bid_price_rolled_std',\n",
       "       'ask_price_rolled_std', 'wap_rolled_std', 'wap_time_decay',\n",
       "       'moving_avg_5', 'moving_avg_10', 'ewma_10', 'volatility_10',\n",
       "       'moving_avg_20', 'ewma_20', 'macd', 'rolling_std', 'rolling_corr',\n",
       "       'rsi_14', 'wap_skewness', 'wap_kurtosis', 'volatility_clustering',\n",
       "       'imb_s1', 'imb_s2', 'volume', 'mid_price', 'liquidity_imbalance',\n",
       "       'matched_imbalance', 'all_size', 'imbalance_size_for_buy_sell',\n",
       "       'price_spread', 'price_pressure', 'market_urgency',\n",
       "       'cumsum_buy_imbalance', 'cumsum_sell_imbalance', 'order_flow_imbalance',\n",
       "       'volume_price_interaction', 'wap_lagged', 'price_shock', 'volume_shock',\n",
       "       'date_sin', 'date_cos', 'seconds_sin', 'seconds_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "99e9204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [06:57<00:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most important 15 features：\n",
      "market_urgency: 0.7511\n",
      "near_price: 0.0384\n",
      "price_spread: 0.0157\n",
      "price_pressure: 0.0133\n",
      "reference_price: 0.0125\n",
      "imbalance_size_for_buy_sell: 0.0122\n",
      "wap_lagged: 0.0114\n",
      "ask_price: 0.0111\n",
      "bid_price: 0.0104\n",
      "wap_time_decay: 0.0091\n",
      "mid_price: 0.0077\n",
      "matched_imbalance: 0.0075\n",
      "imb_s2: 0.0072\n",
      "rsi_14: 0.0067\n",
      "wap: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  \n",
    "\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "with tqdm(total=100, desc=\"Training\") as pbar:  \n",
    "    model.fit(X, y)\n",
    "    pbar.update(100)  \n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "sorted_feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"the most important 20 features：\")\n",
    "for index, row in sorted_feature_importance_df.head(15).iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5e58e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Explained Variance Ratio\n",
      "0                  stock_id                  0.199686\n",
      "1            imbalance_size                  0.078950\n",
      "2   imbalance_buy_sell_flag                  0.071550\n",
      "3           reference_price                  0.062168\n",
      "4              matched_size                  0.052176\n",
      "5                 far_price                  0.046848\n",
      "6                near_price                  0.043406\n",
      "7                 bid_price                  0.034377\n",
      "8                  bid_size                  0.023874\n",
      "9                 ask_price                  0.023148\n",
      "10                 ask_size                  0.022195\n",
      "11                      wap                  0.020959\n",
      "12                  time_id                  0.018095\n",
      "13     is_far_price_missing                  0.017438\n",
      "14    is_near_price_missing                  0.017139\n",
      "15           is_wap_missing                  0.016689\n",
      "16                     high                  0.015644\n",
      "17                      low                  0.015106\n",
      "18              fib_level_1                  0.014916\n",
      "19              fib_level_2                  0.014812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = train.drop(columns=[\"target\"])  \n",
    "y = train[\"target\"]  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_components = X.shape[1]  \n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "feature_names = X.columns \n",
    "explained_variance_df = pd.DataFrame({'Feature': feature_names, 'Explained Variance Ratio': explained_variance_ratio})\n",
    "\n",
    "print(explained_variance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7a821db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most important 20 features：\n",
      "reference_price: 1.8887\n",
      "market_urgency: -1.6202\n",
      "bid_price: -0.9532\n",
      "ask_price: -0.9010\n",
      "wap: -0.7858\n",
      "bid_price_rolled_std: 0.5279\n",
      "ask_price_rolled_std: -0.4878\n",
      "wap_time_decay: 0.2803\n",
      "imbalance_size_for_buy_sell: 0.1954\n",
      "moving_avg_20: 0.1305\n",
      "seconds_cos: 0.1301\n",
      "imbalance_buy_sell_flag: 0.1194\n",
      "near_price: 0.0919\n",
      "matched_imbalance: 0.0662\n",
      "date_cos: -0.0657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "feature_coefficients = {}\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    if lasso.coef_[i] != 0:\n",
    "        feature_coefficients[X.columns[i]] = lasso.coef_[i]\n",
    "\n",
    "sorted_features = sorted(feature_coefficients.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"the most important 20 features：\")\n",
    "for feature, coef in sorted_features[:15]:\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "56aeadc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Importance\n",
      "0                      stock_id       491.0\n",
      "1                imbalance_size       282.0\n",
      "3               reference_price       249.0\n",
      "4                  matched_size       233.0\n",
      "46                       imb_s2       219.0\n",
      "53               market_urgency       173.0\n",
      "17                          low       162.0\n",
      "45                       imb_s1       162.0\n",
      "50  imbalance_size_for_buy_sell       157.0\n",
      "8                      bid_size       152.0\n",
      "25          bid_size_rolled_sum       151.0\n",
      "21                      support       139.0\n",
      "64                  seconds_cos       132.0\n",
      "27   reference_price_rolled_std       126.0\n",
      "12                      time_id       125.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  \n",
    "    'eval_metric': 'rmse',           \n",
    "    'max_depth': 10,                  \n",
    "    'n_estimators': 4000,             \n",
    "    'learning_rate': 0.03          \n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain)\n",
    "\n",
    "importance = model.get_fscore()\n",
    "importance_df = pd.DataFrame({'Feature': list(importance.keys()), 'Importance': list(importance.values())})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_15_features = importance_df.head(15)\n",
    "print(top_15_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d0f12da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature           VIF\n",
      "23                    mid_price           inf\n",
      "16                    bid_price           inf\n",
      "5                market_urgency           inf\n",
      "6                  price_spread           inf\n",
      "30                          wap           inf\n",
      "15                    ask_price           inf\n",
      "24                       imb_s2  2.875898e+06\n",
      "34            matched_imbalance  5.201342e+05\n",
      "1                   fib_level_2  8.742007e+01\n",
      "0                   fib_level_1  6.934040e+01\n",
      "4               reference_price  6.928146e+01\n",
      "28        is_near_price_missing  3.720344e+01\n",
      "22               wap_time_decay  3.380660e+01\n",
      "27         is_far_price_missing  3.351423e+01\n",
      "14                   wap_lagged  2.386516e+01\n",
      "31                  seconds_sin  4.688452e+00\n",
      "25                       imb_s1  2.206637e+00\n",
      "12          bid_size_rolled_sum  1.934492e+00\n",
      "18                     bid_size  1.865750e+00\n",
      "10    imbalance_size_rolled_sum  1.770447e+00\n",
      "13          ask_size_rolled_sum  1.730051e+00\n",
      "33                moving_avg_20  1.646167e+00\n",
      "26                       rsi_14  1.624199e+00\n",
      "19                     ask_size  1.600771e+00\n",
      "3                 volatility_10  1.468370e+00\n",
      "9       imbalance_buy_sell_flag  1.446081e+00\n",
      "11      matched_size_rolled_sum  1.409192e+00\n",
      "7                price_pressure  1.372982e+00\n",
      "20                   near_price  1.298809e+00\n",
      "32                  seconds_cos  1.166717e+00\n",
      "8   imbalance_size_for_buy_sell  1.139475e+00\n",
      "21                      time_id  1.126708e+00\n",
      "35                     date_cos  1.043009e+00\n",
      "2                      stock_id  1.009566e+00\n",
      "29               is_wap_missing  1.000962e+00\n",
      "17                    far_price  1.000661e+00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "features = [\n",
    "    'fib_level_1', 'fib_level_2', 'stock_id', 'volatility_10', 'reference_price',\n",
    "    'market_urgency', 'price_spread', 'price_pressure', 'imbalance_size_for_buy_sell',\n",
    "    'imbalance_buy_sell_flag', 'imbalance_size_rolled_sum', 'matched_size_rolled_sum',\n",
    "    'bid_size_rolled_sum', 'ask_size_rolled_sum', 'wap_lagged', 'ask_price', 'bid_price',\n",
    "    'far_price', 'bid_size', 'ask_size', 'near_price', 'time_id', 'wap_time_decay',\n",
    "    'mid_price', 'imb_s2', 'imb_s1', 'rsi_14', 'is_far_price_missing', 'is_near_price_missing',\n",
    "    'is_wap_missing', 'wap', 'seconds_sin', 'seconds_cos', 'moving_avg_20',\n",
    "    'matched_imbalance', 'date_cos'\n",
    "]\n",
    "\n",
    "df = train[features]\n",
    "\n",
    "def calculate_vif_sorted(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "    vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)  # 對VIF值進行降序排序\n",
    "    return vif_data\n",
    "\n",
    "vif_df_sorted = calculate_vif_sorted(df)\n",
    "print(vif_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "75ab2727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>price_spread</th>\n",
       "      <th>price_pressure</th>\n",
       "      <th>imbalance_size_for_buy_sell</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>imbalance_size_rolled_sum</th>\n",
       "      <th>matched_size_rolled_sum</th>\n",
       "      <th>bid_size_rolled_sum</th>\n",
       "      <th>ask_size_rolled_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>near_price</th>\n",
       "      <th>time_id</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>is_wap_missing</th>\n",
       "      <th>seconds_cos</th>\n",
       "      <th>moving_avg_20</th>\n",
       "      <th>date_cos</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.136944e-16</td>\n",
       "      <td>-0.571684</td>\n",
       "      <td>-0.093875</td>\n",
       "      <td>0.157286</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.257681</td>\n",
       "      <td>-0.277605</td>\n",
       "      <td>-0.496977</td>\n",
       "      <td>-0.578446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.067374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.566576e+00</td>\n",
       "      <td>0.535598</td>\n",
       "      <td>-0.124936</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.282653</td>\n",
       "      <td>-0.289969</td>\n",
       "      <td>-0.607903</td>\n",
       "      <td>-0.557256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399984</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099903</td>\n",
       "      <td>-9.741489</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.566532e+00</td>\n",
       "      <td>0.799333</td>\n",
       "      <td>-0.116865</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.281524</td>\n",
       "      <td>-0.289782</td>\n",
       "      <td>-0.540822</td>\n",
       "      <td>-0.560073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120927</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.099291</td>\n",
       "      <td>-9.741489</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.566412e+00</td>\n",
       "      <td>-0.569671</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>-0.541174</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.185289</td>\n",
       "      <td>-0.272329</td>\n",
       "      <td>-0.609658</td>\n",
       "      <td>0.244787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407283</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019992</td>\n",
       "      <td>4.071781</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.566397e+00</td>\n",
       "      <td>0.249718</td>\n",
       "      <td>-0.116455</td>\n",
       "      <td>-0.010555</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.280325</td>\n",
       "      <td>-0.272886</td>\n",
       "      <td>-0.582301</td>\n",
       "      <td>-0.592546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293478</td>\n",
       "      <td>1.709458e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.167087</td>\n",
       "      <td>4.094982</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  volatility_10  price_spread  price_pressure  \\\n",
       "0         0   2.136944e-16     -0.571684       -0.093875   \n",
       "1         1  -1.566576e+00      0.535598       -0.124936   \n",
       "2         2  -1.566532e+00      0.799333       -0.116865   \n",
       "3         3  -1.566412e+00     -0.569671        0.011744   \n",
       "4         4  -1.566397e+00      0.249718       -0.116455   \n",
       "\n",
       "   imbalance_size_for_buy_sell  imbalance_buy_sell_flag  \\\n",
       "0                     0.157286                        1   \n",
       "1                     0.002441                       -1   \n",
       "2                    -0.003863                       -1   \n",
       "3                    -0.541174                       -1   \n",
       "4                    -0.010555                       -1   \n",
       "\n",
       "   imbalance_size_rolled_sum  matched_size_rolled_sum  bid_size_rolled_sum  \\\n",
       "0                  -0.257681                -0.277605            -0.496977   \n",
       "1                  -0.282653                -0.289969            -0.607903   \n",
       "2                  -0.281524                -0.289782            -0.540822   \n",
       "3                  -0.185289                -0.272329            -0.609658   \n",
       "4                  -0.280325                -0.272886            -0.582301   \n",
       "\n",
       "   ask_size_rolled_sum  ...  bid_size    near_price  time_id  mid_price  \\\n",
       "0            -0.578446  ...  0.061469  1.709458e-14        0  -0.067374   \n",
       "1            -0.557256  ... -0.399984  1.709458e-14        0   0.099903   \n",
       "2            -0.560073  ... -0.120927  1.709458e-14        0  -0.099291   \n",
       "3             0.244787  ... -0.407283  1.709458e-14        0   0.019992   \n",
       "4            -0.592546  ... -0.293478  1.709458e-14        0  -0.167087   \n",
       "\n",
       "     rsi_14  is_wap_missing  seconds_cos  moving_avg_20  date_cos    target  \n",
       "0  0.000000               0          1.0      -0.052494       1.0 -3.029704  \n",
       "1 -9.741489               0          1.0      -0.052537       1.0 -5.519986  \n",
       "2 -9.741489               0          1.0      -0.052589       1.0 -8.389950  \n",
       "3  4.071781               0          1.0      -0.052494       1.0 -4.010200  \n",
       "4  4.094982               0          1.0      -0.052436       1.0 -7.349849  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_keep = [\n",
    "'stock_id', \n",
    "'volatility_10', \n",
    "'price_spread', \n",
    "'price_pressure', \n",
    "'imbalance_size_for_buy_sell',\n",
    "'imbalance_buy_sell_flag', \n",
    "'imbalance_size_rolled_sum', \n",
    "'matched_size_rolled_sum',\n",
    "'bid_size_rolled_sum', \n",
    "'ask_size_rolled_sum', \n",
    "'wap_lagged',\n",
    "'far_price', \n",
    "'bid_size', \n",
    "'near_price', \n",
    "'time_id', \n",
    "'mid_price', \n",
    "'rsi_14', \n",
    "'is_wap_missing',  \n",
    "'seconds_cos', \n",
    "'moving_avg_20',\n",
    "'date_cos',\n",
    "'target'\n",
    "]\n",
    "\n",
    "train = train[features_to_keep]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df68c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20972/20972 [==============================] - 48s 2ms/step - loss: 80.0513 - val_loss: 79.5892\n",
      "Epoch 2/50\n",
      "20972/20972 [==============================] - 53s 3ms/step - loss: 80.0032 - val_loss: 79.4686\n",
      "Epoch 3/50\n",
      "20972/20972 [==============================] - 85s 4ms/step - loss: 79.8209 - val_loss: 79.2765\n",
      "Epoch 4/50\n",
      "20972/20972 [==============================] - 81s 4ms/step - loss: 79.6467 - val_loss: 79.2232\n",
      "Epoch 5/50\n",
      "20972/20972 [==============================] - 72s 3ms/step - loss: 79.5570 - val_loss: 79.0877\n",
      "Epoch 6/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.3496 - val_loss: 78.7389\n",
      "Epoch 7/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.2993 - val_loss: 78.3324\n",
      "Epoch 8/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.3107 - val_loss: 78.4307\n",
      "Epoch 9/50\n",
      "20972/20972 [==============================] - 67s 3ms/step - loss: 79.3095 - val_loss: 79.8355\n",
      "Epoch 10/50\n",
      "20972/20972 [==============================] - 67s 3ms/step - loss: 79.3584 - val_loss: 77.8478\n",
      "Epoch 11/50\n",
      "20972/20972 [==============================] - 67s 3ms/step - loss: 79.2337 - val_loss: 78.6005\n",
      "Epoch 12/50\n",
      "20972/20972 [==============================] - 67s 3ms/step - loss: 79.1234 - val_loss: 78.3428\n",
      "Epoch 13/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.2013 - val_loss: 78.0976\n",
      "Epoch 14/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.1173 - val_loss: 77.8532\n",
      "Epoch 15/50\n",
      "20972/20972 [==============================] - 65s 3ms/step - loss: 79.2170 - val_loss: 78.3791\n",
      "Epoch 16/50\n",
      "20972/20972 [==============================] - 83s 4ms/step - loss: 79.1453 - val_loss: 78.2935\n",
      "Epoch 17/50\n",
      "20972/20972 [==============================] - 73s 3ms/step - loss: 79.0395 - val_loss: 77.9701\n",
      "Epoch 18/50\n",
      "20972/20972 [==============================] - 70s 3ms/step - loss: 79.0332 - val_loss: 78.4009\n",
      "Epoch 19/50\n",
      "20972/20972 [==============================] - 69s 3ms/step - loss: 79.0062 - val_loss: 78.4068\n",
      "Epoch 20/50\n",
      "20972/20972 [==============================] - 66s 3ms/step - loss: 79.0003 - val_loss: 78.0388\n",
      "6554/6554 [==============================] - 11s 1ms/step\n",
      "Root Mean Squared Error: 8.87521376231561\n",
      "Mean Absolute Error: 5.796060174346662\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "time_series_features = train[['stock_id',\n",
    "'volatility_10',\n",
    "'reference_price',    \n",
    "'market_urgency',\n",
    "'price_spread',\n",
    "'price_pressure',\n",
    "'imbalance_size_for_buy_sell',\n",
    "'imbalance_buy_sell_flag',\n",
    "'imbalance_size_rolled_sum',\n",
    "'matched_size_rolled_sum',\n",
    "'bid_size_rolled_sum',\n",
    "'ask_size_rolled_sum',\n",
    "'wap_lagged',\n",
    "'ask_price',\n",
    "'bid_price',\n",
    "'far_price',\n",
    "'bid_size',\n",
    "'ask_size',\n",
    "'near_price',\n",
    "'time_id',\n",
    "'wap_time_decay',\n",
    "'mid_price',\n",
    "'imb_s2',\n",
    "'imb_s1',\n",
    "'rsi_14',\n",
    "'wap',\n",
    "'seconds_sin',\n",
    "'seconds_cos',\n",
    "'moving_avg_20',\n",
    "'near_price',\n",
    "'matched_imbalance',\n",
    "'date_cos']]\n",
    "\n",
    "target = train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(time_series_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train model with early stopping\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\90607\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/100\n",
      "20972/20972 [==============================] - 114s 5ms/step - loss: 80.1047 - val_loss: 79.0262\n",
      "Epoch 2/100\n",
      "20972/20972 [==============================] - 106s 5ms/step - loss: 79.8449 - val_loss: 78.8940\n",
      "Epoch 3/100\n",
      "20972/20972 [==============================] - 86s 4ms/step - loss: 79.4708 - val_loss: 78.7206\n",
      "Epoch 4/100\n",
      "20972/20972 [==============================] - 62s 3ms/step - loss: 79.1069 - val_loss: 78.5457\n",
      "Epoch 5/100\n",
      "20972/20972 [==============================] - 81s 4ms/step - loss: 78.6976 - val_loss: 78.7931\n",
      "Epoch 6/100\n",
      "20972/20972 [==============================] - 74s 4ms/step - loss: 78.3076 - val_loss: 78.4550\n",
      "Epoch 7/100\n",
      "20972/20972 [==============================] - 270s 13ms/step - loss: 77.8594 - val_loss: 78.2062\n",
      "Epoch 8/100\n",
      "20972/20972 [==============================] - 96s 5ms/step - loss: 77.5195 - val_loss: 78.0972\n",
      "Epoch 9/100\n",
      "20972/20972 [==============================] - 103s 5ms/step - loss: 77.1201 - val_loss: 77.5942\n",
      "Epoch 10/100\n",
      "20972/20972 [==============================] - 109s 5ms/step - loss: 76.7706 - val_loss: 77.7572\n",
      "Epoch 11/100\n",
      "20972/20972 [==============================] - 113s 5ms/step - loss: 76.5282 - val_loss: 77.5393\n",
      "Epoch 12/100\n",
      "20972/20972 [==============================] - 110s 5ms/step - loss: 76.3079 - val_loss: 77.4359\n",
      "Epoch 13/100\n",
      "20972/20972 [==============================] - 105s 5ms/step - loss: 76.0212 - val_loss: 78.5512\n",
      "Epoch 14/100\n",
      "20972/20972 [==============================] - 117s 6ms/step - loss: 75.9347 - val_loss: 77.2517\n",
      "Epoch 15/100\n",
      "20972/20972 [==============================] - 92s 4ms/step - loss: 75.7555 - val_loss: 77.4243\n",
      "Epoch 16/100\n",
      "20972/20972 [==============================] - 63s 3ms/step - loss: 75.6321 - val_loss: 77.2672\n",
      "Epoch 17/100\n",
      "20972/20972 [==============================] - 41s 2ms/step - loss: 75.4851 - val_loss: 77.3633\n",
      "Epoch 18/100\n",
      "20972/20972 [==============================] - 54s 3ms/step - loss: 75.2720 - val_loss: 77.2951\n",
      "Epoch 19/100\n",
      "20964/20972 [============================>.] - ETA: 0s - loss: 75.1900Restoring model weights from the end of the best epoch: 14.\n",
      "20972/20972 [==============================] - 44s 2ms/step - loss: 75.1958 - val_loss: 77.5585\n",
      "Epoch 19: early stopping\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 8, 64)             6592      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 4, 64)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 50)                12850     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19493 (76.14 KB)\n",
      "Trainable params: 19493 (76.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "6554/6554 [==============================] - 6s 943us/step - loss: 79.3790\n",
      "6554/6554 [==============================] - 6s 959us/step\n",
      "Root Mean Squared Error: 8.909479414434584\n",
      "Mean Absolute Error: 5.873424530126088\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "time_series_features = train[['stock_id',\n",
    "'volatility_10',\n",
    "'reference_price',    \n",
    "'market_urgency',\n",
    "'price_spread',\n",
    "'price_pressure',\n",
    "'imbalance_size_for_buy_sell',\n",
    "'imbalance_buy_sell_flag',\n",
    "'imbalance_size_rolled_sum',\n",
    "'matched_size_rolled_sum',\n",
    "'bid_size_rolled_sum',\n",
    "'ask_size_rolled_sum',\n",
    "'wap_lagged',\n",
    "'ask_price',\n",
    "'bid_price',\n",
    "'far_price',\n",
    "'bid_size',\n",
    "'ask_size',\n",
    "'near_price',\n",
    "'time_id',\n",
    "'wap_time_decay',\n",
    "'mid_price',\n",
    "'imb_s2',\n",
    "'imb_s1',\n",
    "'rsi_14',\n",
    "'wap',\n",
    "'seconds_sin',\n",
    "'seconds_cos',\n",
    "'moving_avg_20',\n",
    "'near_price',\n",
    "'matched_imbalance',\n",
    "'date_cos']]\n",
    "\n",
    "target = train['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(time_series_features.values)\n",
    "\n",
    "time_steps = 10\n",
    "samples = len(train) - time_steps\n",
    "num_features = len(time_series_features.columns)\n",
    "\n",
    "X = np.zeros((samples, time_steps, num_features))\n",
    "\n",
    "for i in range(samples):\n",
    "    X[i] = scaled_features[i:i+time_steps]\n",
    "\n",
    "Y = target[time_steps:].values\n",
    "assert len(Y) == len(X), \"The lengths of X and Y do not match.\"\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(time_steps, len(time_series_features.columns))))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
    "model.summary()\n",
    "\n",
    "test_loss = model.evaluate(X_test, Y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 32)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 8, 64)                6208      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 4, 64)                0         ['conv1d_2[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 50)                   16600     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 256)                  0         ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 306)                  0         ['lstm_5[0][0]',              \n",
      " )                                                                   'flatten_11[0][0]']          \n",
      "                                                                                                  \n",
      " dense_42 (Dense)            (None, 50)                   15350     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_43 (Dense)            (None, 1)                    51        ['dense_42[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38209 (149.25 KB)\n",
      "Trainable params: 38209 (149.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "26215/26215 [==============================] - 87s 3ms/step - loss: 79.8799 - val_loss: 80.4895\n",
      "Epoch 2/100\n",
      "26215/26215 [==============================] - 84s 3ms/step - loss: 79.4837 - val_loss: 80.1194\n",
      "Epoch 3/100\n",
      "26215/26215 [==============================] - 156s 6ms/step - loss: 78.7545 - val_loss: 79.5694\n",
      "Epoch 4/100\n",
      "26215/26215 [==============================] - 98s 4ms/step - loss: 77.7643 - val_loss: 79.2121\n",
      "Epoch 5/100\n",
      "26215/26215 [==============================] - 87s 3ms/step - loss: 76.8307 - val_loss: 78.8742\n",
      "Epoch 6/100\n",
      "26215/26215 [==============================] - 80s 3ms/step - loss: 75.8442 - val_loss: 78.2739\n",
      "Epoch 7/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 75.0250 - val_loss: 78.1934\n",
      "Epoch 8/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 74.3411 - val_loss: 78.4487\n",
      "Epoch 9/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 73.7257 - val_loss: 78.0117\n",
      "Epoch 10/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 73.1358 - val_loss: 77.6202\n",
      "Epoch 11/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 72.7183 - val_loss: 78.0132\n",
      "Epoch 12/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 72.2512 - val_loss: 77.2975\n",
      "Epoch 13/100\n",
      "26215/26215 [==============================] - 43874s 2s/step - loss: 71.8355 - val_loss: 76.6599\n",
      "Epoch 14/100\n",
      "26215/26215 [==============================] - 84s 3ms/step - loss: 71.3657 - val_loss: 76.5664\n",
      "Epoch 15/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 71.1673 - val_loss: 76.2888\n",
      "Epoch 16/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 70.7211 - val_loss: 76.2704\n",
      "Epoch 17/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 70.5513 - val_loss: 76.2734\n",
      "Epoch 18/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 70.2900 - val_loss: 76.7718\n",
      "Epoch 19/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 70.1005 - val_loss: 76.4749\n",
      "Epoch 20/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 69.9374 - val_loss: 75.9062\n",
      "Epoch 21/100\n",
      "26215/26215 [==============================] - 77s 3ms/step - loss: 69.7076 - val_loss: 76.5787\n",
      "Epoch 22/100\n",
      "26215/26215 [==============================] - 77s 3ms/step - loss: 69.3617 - val_loss: 76.5831\n",
      "Epoch 23/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 69.2043 - val_loss: 75.9867\n",
      "Epoch 24/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 69.1521 - val_loss: 75.6612\n",
      "Epoch 25/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 69.0262 - val_loss: 75.5890\n",
      "Epoch 26/100\n",
      "26215/26215 [==============================] - 92s 4ms/step - loss: 68.8349 - val_loss: 75.9105\n",
      "Epoch 27/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 68.7434 - val_loss: 76.6614\n",
      "Epoch 28/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 68.6400 - val_loss: 76.5958\n",
      "Epoch 29/100\n",
      "26215/26215 [==============================] - 79s 3ms/step - loss: 68.4690 - val_loss: 75.7554\n",
      "Epoch 30/100\n",
      "26215/26215 [==============================] - 78s 3ms/step - loss: 68.5897 - val_loss: 76.2809\n",
      "6554/6554 [==============================] - 9s 1ms/step\n",
      "Root Mean Squared Error: 8.694201234454562\n",
      "Mean Absolute Error: 5.8321050917350945\n"
     ]
    }
   ],
   "source": [
    "#CNN+LSTM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "time_series_features = train[['stock_id',\n",
    "'volatility_10',\n",
    "'reference_price',    \n",
    "'market_urgency',\n",
    "'price_spread',\n",
    "'price_pressure',\n",
    "'imbalance_size_for_buy_sell',\n",
    "'imbalance_buy_sell_flag',\n",
    "'imbalance_size_rolled_sum',\n",
    "'matched_size_rolled_sum',\n",
    "'bid_size_rolled_sum',\n",
    "'ask_size_rolled_sum',\n",
    "'wap_lagged',\n",
    "'ask_price',\n",
    "'bid_price',\n",
    "'far_price',\n",
    "'bid_size',\n",
    "'ask_size',\n",
    "'near_price',\n",
    "'time_id',\n",
    "'wap_time_decay',\n",
    "'mid_price',\n",
    "'imb_s2',\n",
    "'imb_s1',\n",
    "'rsi_14',\n",
    "'wap',\n",
    "'seconds_sin',\n",
    "'seconds_cos',\n",
    "'moving_avg_20',\n",
    "'near_price',\n",
    "'matched_imbalance',\n",
    "'date_cos']]\n",
    "\n",
    "target = train['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(time_series_features.values)\n",
    "\n",
    "time_steps = 10\n",
    "samples = len(train) - time_steps\n",
    "num_features = len(time_series_features.columns)\n",
    "X = np.zeros((samples, time_steps, num_features))\n",
    "\n",
    "for i in range(samples):\n",
    "    X[i] = scaled_features[i:i+time_steps]\n",
    "\n",
    "Y = target[time_steps:].values\n",
    "assert len(Y) == len(X), \"The lengths of X and Y do not match.\"\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "features = 32\n",
    "\n",
    "Y_train_seq = Y_train\n",
    "Y_test_seq = Y_test\n",
    "\n",
    "assert len(X_train) == len(Y_train_seq), \"Mismatch in train sequence lengths.\"\n",
    "assert len(X_test) == len(Y_test_seq), \"Mismatch in test sequence lengths.\"\n",
    "\n",
    "input_layer = Input(shape=(time_steps, features))\n",
    "lstm_layer = LSTM(50, return_sequences=False)(input_layer)\n",
    "cnn_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
    "cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "cnn_layer = Flatten()(cnn_layer)\n",
    "combined = Concatenate()([lstm_layer, cnn_layer])\n",
    "dense_layer = Dense(50, activation='relu')(combined)\n",
    "output_layer = Dense(1)(dense_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train_seq, epochs=100, batch_size=32, \n",
    "                    validation_data=(X_test, Y_test_seq), \n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_seq, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "mae = mean_absolute_error(Y_test_seq, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\90607\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6999\n",
      "[LightGBM] [Info] Number of data points in the train set: 838860, number of used features: 34\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Ti Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 33 dense feature groups (28.80 MB) transferred to GPU in 0.017288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Info] Start training from score -0.069737\n",
      "Root Mean Squared Error: 8.909479414434584\n",
      "Mean Squared Error (MSE): 68.61060498780951\n",
      "Mean Absolute Error (MAE): 5.357441633545923\n",
      "R-squared (R^2): 0.14823609658329695\n"
     ]
    }
   ],
   "source": [
    "#LightGBM\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "X = train.drop('target', axis=1)  \n",
    "y = train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"mae\",\n",
    "    \"n_estimators\": 5000,\n",
    "    \"num_leaves\": 256,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"learning_rate\": 0.00871,\n",
    "    \"n_jobs\": 4,\n",
    "    \"device\": \"gpu\",\n",
    "    \"verbosity\": 1,  \n",
    "    \"importance_type\": \"gain\",\n",
    "}\n",
    "\n",
    "def early_stopping_callback(env):\n",
    "    if env.iteration >= 100 and len(env.evaluation_result_list) >= 101 and \\\n",
    "            env.evaluation_result_list[-1][2] <= env.evaluation_result_list[-101][2]:\n",
    "        raise Exception(\"Early stopping\")\n",
    "\n",
    "model = lgb.train(lgb_params, train_data, valid_sets=[train_data, test_data], num_boost_round=5000,\n",
    "                  callbacks=[early_stopping_callback])\n",
    "\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4ffabf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 8.9294882\ttest: 8.9623235\tbest: 8.9623235 (0)\ttotal: 41.5ms\tremaining: 13m 49s\n",
      "100:\tlearn: 8.6737866\ttest: 8.7802789\tbest: 8.7802789 (100)\ttotal: 2.73s\tremaining: 8m 58s\n",
      "200:\tlearn: 8.5728657\ttest: 8.7229402\tbest: 8.7229402 (200)\ttotal: 5.36s\tremaining: 8m 47s\n",
      "300:\tlearn: 8.4948418\ttest: 8.6746915\tbest: 8.6746915 (300)\ttotal: 8.22s\tremaining: 8m 58s\n",
      "400:\tlearn: 8.4336025\ttest: 8.6388244\tbest: 8.6388244 (400)\ttotal: 11s\tremaining: 8m 56s\n",
      "500:\tlearn: 8.3783744\ttest: 8.6050211\tbest: 8.6050211 (500)\ttotal: 13.7s\tremaining: 8m 51s\n",
      "600:\tlearn: 8.3299354\ttest: 8.5772253\tbest: 8.5772253 (600)\ttotal: 16.2s\tremaining: 8m 44s\n",
      "700:\tlearn: 8.2864969\ttest: 8.5496713\tbest: 8.5496713 (700)\ttotal: 18.7s\tremaining: 8m 34s\n",
      "800:\tlearn: 8.2442455\ttest: 8.5246467\tbest: 8.5246467 (800)\ttotal: 21.2s\tremaining: 8m 29s\n",
      "900:\tlearn: 8.2051541\ttest: 8.5005905\tbest: 8.5005905 (900)\ttotal: 23.8s\tremaining: 8m 24s\n",
      "1000:\tlearn: 8.1662937\ttest: 8.4773516\tbest: 8.4773516 (1000)\ttotal: 26.4s\tremaining: 8m 21s\n",
      "1100:\tlearn: 8.1308672\ttest: 8.4558844\tbest: 8.4558844 (1100)\ttotal: 29s\tremaining: 8m 18s\n",
      "1200:\tlearn: 8.0978812\ttest: 8.4370444\tbest: 8.4370444 (1200)\ttotal: 31.5s\tremaining: 8m 12s\n",
      "1300:\tlearn: 8.0681382\ttest: 8.4193056\tbest: 8.4193056 (1300)\ttotal: 34s\tremaining: 8m 8s\n",
      "1400:\tlearn: 8.0383718\ttest: 8.4023812\tbest: 8.4023812 (1400)\ttotal: 36.5s\tremaining: 8m 4s\n",
      "1500:\tlearn: 8.0099774\ttest: 8.3857569\tbest: 8.3857569 (1500)\ttotal: 39s\tremaining: 8m\n",
      "1600:\tlearn: 7.9829712\ttest: 8.3708149\tbest: 8.3707828 (1599)\ttotal: 41.5s\tremaining: 7m 57s\n",
      "1700:\tlearn: 7.9560161\ttest: 8.3561799\tbest: 8.3561799 (1700)\ttotal: 44s\tremaining: 7m 53s\n",
      "1800:\tlearn: 7.9293085\ttest: 8.3412543\tbest: 8.3412543 (1800)\ttotal: 46.5s\tremaining: 7m 49s\n",
      "1900:\tlearn: 7.9034989\ttest: 8.3261211\tbest: 8.3261211 (1900)\ttotal: 49s\tremaining: 7m 46s\n",
      "2000:\tlearn: 7.8789955\ttest: 8.3137176\tbest: 8.3137176 (2000)\ttotal: 51.5s\tremaining: 7m 43s\n",
      "2100:\tlearn: 7.8550251\ttest: 8.3015321\tbest: 8.3015321 (2100)\ttotal: 53.9s\tremaining: 7m 39s\n",
      "2200:\tlearn: 7.8310329\ttest: 8.2878197\tbest: 8.2878197 (2200)\ttotal: 56.5s\tremaining: 7m 36s\n",
      "2300:\tlearn: 7.8098812\ttest: 8.2765757\tbest: 8.2765757 (2300)\ttotal: 58.9s\tremaining: 7m 33s\n",
      "2400:\tlearn: 7.7892354\ttest: 8.2649576\tbest: 8.2649576 (2400)\ttotal: 1m 1s\tremaining: 7m 30s\n",
      "2500:\tlearn: 7.7677868\ttest: 8.2533887\tbest: 8.2533887 (2500)\ttotal: 1m 3s\tremaining: 7m 27s\n",
      "2600:\tlearn: 7.7468865\ttest: 8.2411569\tbest: 8.2411569 (2600)\ttotal: 1m 6s\tremaining: 7m 24s\n",
      "2700:\tlearn: 7.7257749\ttest: 8.2301975\tbest: 8.2301975 (2700)\ttotal: 1m 8s\tremaining: 7m 21s\n",
      "2800:\tlearn: 7.7060717\ttest: 8.2199700\tbest: 8.2199591 (2799)\ttotal: 1m 11s\tremaining: 7m 18s\n",
      "2900:\tlearn: 7.6865858\ttest: 8.2095199\tbest: 8.2095199 (2900)\ttotal: 1m 13s\tremaining: 7m 15s\n",
      "3000:\tlearn: 7.6674575\ttest: 8.1993549\tbest: 8.1993549 (3000)\ttotal: 1m 16s\tremaining: 7m 13s\n",
      "3100:\tlearn: 7.6478944\ttest: 8.1902841\tbest: 8.1902841 (3100)\ttotal: 1m 19s\tremaining: 7m 11s\n",
      "3200:\tlearn: 7.6297892\ttest: 8.1819160\tbest: 8.1819160 (3200)\ttotal: 1m 21s\tremaining: 7m 8s\n",
      "3300:\tlearn: 7.6119470\ttest: 8.1723128\tbest: 8.1723128 (3300)\ttotal: 1m 24s\tremaining: 7m 5s\n",
      "3400:\tlearn: 7.5940845\ttest: 8.1622008\tbest: 8.1622008 (3400)\ttotal: 1m 26s\tremaining: 7m 3s\n",
      "3500:\tlearn: 7.5766399\ttest: 8.1526248\tbest: 8.1526248 (3500)\ttotal: 1m 29s\tremaining: 7m\n",
      "3600:\tlearn: 7.5596978\ttest: 8.1441179\tbest: 8.1441179 (3600)\ttotal: 1m 31s\tremaining: 6m 58s\n",
      "3700:\tlearn: 7.5432450\ttest: 8.1364099\tbest: 8.1364099 (3700)\ttotal: 1m 34s\tremaining: 6m 55s\n",
      "3800:\tlearn: 7.5261937\ttest: 8.1280220\tbest: 8.1279601 (3799)\ttotal: 1m 36s\tremaining: 6m 52s\n",
      "3900:\tlearn: 7.5094892\ttest: 8.1201320\tbest: 8.1199635 (3899)\ttotal: 1m 39s\tremaining: 6m 49s\n",
      "4000:\tlearn: 7.4935340\ttest: 8.1126846\tbest: 8.1126846 (4000)\ttotal: 1m 41s\tremaining: 6m 47s\n",
      "4100:\tlearn: 7.4778726\ttest: 8.1049812\tbest: 8.1049812 (4100)\ttotal: 1m 44s\tremaining: 6m 44s\n",
      "4200:\tlearn: 7.4624721\ttest: 8.0971935\tbest: 8.0971935 (4200)\ttotal: 1m 46s\tremaining: 6m 41s\n",
      "4300:\tlearn: 7.4469550\ttest: 8.0885396\tbest: 8.0885396 (4300)\ttotal: 1m 49s\tremaining: 6m 39s\n",
      "4400:\tlearn: 7.4311577\ttest: 8.0808318\tbest: 8.0808318 (4400)\ttotal: 1m 51s\tremaining: 6m 36s\n",
      "4500:\tlearn: 7.4156839\ttest: 8.0739880\tbest: 8.0739880 (4500)\ttotal: 1m 54s\tremaining: 6m 33s\n",
      "4600:\tlearn: 7.4005269\ttest: 8.0663882\tbest: 8.0663882 (4600)\ttotal: 1m 56s\tremaining: 6m 31s\n",
      "4700:\tlearn: 7.3846101\ttest: 8.0583475\tbest: 8.0583475 (4700)\ttotal: 1m 59s\tremaining: 6m 28s\n",
      "4800:\tlearn: 7.3702495\ttest: 8.0521489\tbest: 8.0521489 (4800)\ttotal: 2m 2s\tremaining: 6m 26s\n",
      "4900:\tlearn: 7.3557847\ttest: 8.0450894\tbest: 8.0450894 (4900)\ttotal: 2m 4s\tremaining: 6m 23s\n",
      "5000:\tlearn: 7.3419647\ttest: 8.0376095\tbest: 8.0376095 (5000)\ttotal: 2m 7s\tremaining: 6m 21s\n",
      "5100:\tlearn: 7.3280977\ttest: 8.0315628\tbest: 8.0315628 (5100)\ttotal: 2m 9s\tremaining: 6m 18s\n",
      "5200:\tlearn: 7.3144282\ttest: 8.0252652\tbest: 8.0252652 (5200)\ttotal: 2m 12s\tremaining: 6m 16s\n",
      "5300:\tlearn: 7.3002748\ttest: 8.0186792\tbest: 8.0186792 (5300)\ttotal: 2m 14s\tremaining: 6m 13s\n",
      "5400:\tlearn: 7.2867938\ttest: 8.0130001\tbest: 8.0130001 (5400)\ttotal: 2m 17s\tremaining: 6m 10s\n",
      "5500:\tlearn: 7.2731806\ttest: 8.0067701\tbest: 8.0067701 (5500)\ttotal: 2m 19s\tremaining: 6m 8s\n",
      "5600:\tlearn: 7.2600151\ttest: 8.0000602\tbest: 8.0000602 (5600)\ttotal: 2m 22s\tremaining: 6m 5s\n",
      "5700:\tlearn: 7.2468903\ttest: 7.9934067\tbest: 7.9934067 (5700)\ttotal: 2m 24s\tremaining: 6m 3s\n",
      "5800:\tlearn: 7.2335261\ttest: 7.9882138\tbest: 7.9882138 (5800)\ttotal: 2m 27s\tremaining: 6m 1s\n",
      "5900:\tlearn: 7.2205186\ttest: 7.9824451\tbest: 7.9824451 (5900)\ttotal: 2m 30s\tremaining: 5m 59s\n",
      "6000:\tlearn: 7.2079024\ttest: 7.9770181\tbest: 7.9770181 (6000)\ttotal: 2m 33s\tremaining: 5m 56s\n",
      "6100:\tlearn: 7.1947930\ttest: 7.9709940\tbest: 7.9709940 (6100)\ttotal: 2m 35s\tremaining: 5m 54s\n",
      "6200:\tlearn: 7.1819784\ttest: 7.9646965\tbest: 7.9646965 (6200)\ttotal: 2m 38s\tremaining: 5m 52s\n",
      "6300:\tlearn: 7.1695587\ttest: 7.9589546\tbest: 7.9589546 (6300)\ttotal: 2m 41s\tremaining: 5m 50s\n",
      "6400:\tlearn: 7.1571145\ttest: 7.9536959\tbest: 7.9536959 (6400)\ttotal: 2m 43s\tremaining: 5m 48s\n",
      "6500:\tlearn: 7.1451278\ttest: 7.9479256\tbest: 7.9479256 (6500)\ttotal: 2m 46s\tremaining: 5m 45s\n",
      "6600:\tlearn: 7.1331161\ttest: 7.9425629\tbest: 7.9425629 (6600)\ttotal: 2m 49s\tremaining: 5m 43s\n",
      "6700:\tlearn: 7.1215380\ttest: 7.9371339\tbest: 7.9371339 (6700)\ttotal: 2m 51s\tremaining: 5m 41s\n",
      "6800:\tlearn: 7.1093525\ttest: 7.9302627\tbest: 7.9302627 (6800)\ttotal: 2m 54s\tremaining: 5m 38s\n",
      "6900:\tlearn: 7.0975338\ttest: 7.9248337\tbest: 7.9248337 (6900)\ttotal: 2m 57s\tremaining: 5m 36s\n",
      "7000:\tlearn: 7.0858050\ttest: 7.9197471\tbest: 7.9197471 (7000)\ttotal: 3m\tremaining: 5m 34s\n",
      "7100:\tlearn: 7.0741795\ttest: 7.9141827\tbest: 7.9141827 (7100)\ttotal: 3m 2s\tremaining: 5m 32s\n",
      "7200:\tlearn: 7.0621980\ttest: 7.9081116\tbest: 7.9080939 (7199)\ttotal: 3m 7s\tremaining: 5m 33s\n",
      "7300:\tlearn: 7.0502825\ttest: 7.9025897\tbest: 7.9025897 (7300)\ttotal: 3m 12s\tremaining: 5m 34s\n",
      "7400:\tlearn: 7.0393630\ttest: 7.8977250\tbest: 7.8977250 (7400)\ttotal: 3m 17s\tremaining: 5m 36s\n",
      "7500:\tlearn: 7.0282507\ttest: 7.8923947\tbest: 7.8923712 (7499)\ttotal: 3m 21s\tremaining: 5m 35s\n",
      "7600:\tlearn: 7.0167460\ttest: 7.8863614\tbest: 7.8863614 (7600)\ttotal: 3m 24s\tremaining: 5m 32s\n",
      "7700:\tlearn: 7.0057299\ttest: 7.8813105\tbest: 7.8813105 (7700)\ttotal: 3m 27s\tremaining: 5m 31s\n",
      "7800:\tlearn: 6.9945007\ttest: 7.8756617\tbest: 7.8756617 (7800)\ttotal: 3m 32s\tremaining: 5m 31s\n",
      "7900:\tlearn: 6.9833560\ttest: 7.8700793\tbest: 7.8700610 (7899)\ttotal: 3m 36s\tremaining: 5m 32s\n",
      "8000:\tlearn: 6.9722798\ttest: 7.8644470\tbest: 7.8644435 (7999)\ttotal: 3m 41s\tremaining: 5m 32s\n",
      "8100:\tlearn: 6.9613843\ttest: 7.8594855\tbest: 7.8594802 (8099)\ttotal: 3m 44s\tremaining: 5m 29s\n",
      "8200:\tlearn: 6.9506261\ttest: 7.8548889\tbest: 7.8548889 (8200)\ttotal: 3m 47s\tremaining: 5m 26s\n",
      "8300:\tlearn: 6.9398038\ttest: 7.8498069\tbest: 7.8498069 (8300)\ttotal: 3m 49s\tremaining: 5m 23s\n",
      "8400:\tlearn: 6.9293064\ttest: 7.8446700\tbest: 7.8446700 (8400)\ttotal: 3m 52s\tremaining: 5m 21s\n",
      "8500:\tlearn: 6.9189160\ttest: 7.8406153\tbest: 7.8406153 (8500)\ttotal: 3m 55s\tremaining: 5m 17s\n",
      "8600:\tlearn: 6.9080862\ttest: 7.8356776\tbest: 7.8356776 (8600)\ttotal: 3m 57s\tremaining: 5m 14s\n",
      "8700:\tlearn: 6.8981373\ttest: 7.8313302\tbest: 7.8313302 (8700)\ttotal: 4m\tremaining: 5m 11s\n",
      "8800:\tlearn: 6.8878929\ttest: 7.8264915\tbest: 7.8264839 (8799)\ttotal: 4m 2s\tremaining: 5m 8s\n",
      "8900:\tlearn: 6.8781267\ttest: 7.8219090\tbest: 7.8219090 (8900)\ttotal: 4m 5s\tremaining: 5m 5s\n",
      "9000:\tlearn: 6.8681912\ttest: 7.8177335\tbest: 7.8177335 (9000)\ttotal: 4m 7s\tremaining: 5m 2s\n",
      "9100:\tlearn: 6.8580412\ttest: 7.8124461\tbest: 7.8124461 (9100)\ttotal: 4m 10s\tremaining: 4m 59s\n",
      "9200:\tlearn: 6.8480059\ttest: 7.8078217\tbest: 7.8078217 (9200)\ttotal: 4m 12s\tremaining: 4m 56s\n",
      "9300:\tlearn: 6.8386578\ttest: 7.8038247\tbest: 7.8038247 (9300)\ttotal: 4m 15s\tremaining: 4m 53s\n",
      "9400:\tlearn: 6.8279377\ttest: 7.7988917\tbest: 7.7988917 (9400)\ttotal: 4m 18s\tremaining: 4m 50s\n",
      "9500:\tlearn: 6.8182498\ttest: 7.7949650\tbest: 7.7949650 (9500)\ttotal: 4m 20s\tremaining: 4m 47s\n",
      "9600:\tlearn: 6.8091513\ttest: 7.7910755\tbest: 7.7910419 (9599)\ttotal: 4m 23s\tremaining: 4m 45s\n",
      "9700:\tlearn: 6.7996993\ttest: 7.7869552\tbest: 7.7869552 (9700)\ttotal: 4m 25s\tremaining: 4m 42s\n",
      "9800:\tlearn: 6.7900050\ttest: 7.7825518\tbest: 7.7825518 (9800)\ttotal: 4m 28s\tremaining: 4m 39s\n",
      "9900:\tlearn: 6.7803433\ttest: 7.7785064\tbest: 7.7785064 (9900)\ttotal: 4m 31s\tremaining: 4m 37s\n",
      "10000:\tlearn: 6.7713152\ttest: 7.7746027\tbest: 7.7746027 (10000)\ttotal: 4m 34s\tremaining: 4m 34s\n",
      "10100:\tlearn: 6.7618634\ttest: 7.7701406\tbest: 7.7701406 (10100)\ttotal: 4m 37s\tremaining: 4m 31s\n",
      "10200:\tlearn: 6.7526058\ttest: 7.7659060\tbest: 7.7659060 (10200)\ttotal: 4m 40s\tremaining: 4m 29s\n",
      "10300:\tlearn: 6.7430115\ttest: 7.7609285\tbest: 7.7609285 (10300)\ttotal: 4m 42s\tremaining: 4m 26s\n",
      "10400:\tlearn: 6.7336907\ttest: 7.7564406\tbest: 7.7564406 (10400)\ttotal: 4m 45s\tremaining: 4m 23s\n",
      "10500:\tlearn: 6.7250702\ttest: 7.7525675\tbest: 7.7525675 (10500)\ttotal: 4m 48s\tremaining: 4m 20s\n",
      "10600:\tlearn: 6.7156814\ttest: 7.7483363\tbest: 7.7482834 (10598)\ttotal: 4m 51s\tremaining: 4m 18s\n",
      "10700:\tlearn: 6.7065363\ttest: 7.7444329\tbest: 7.7444329 (10700)\ttotal: 4m 54s\tremaining: 4m 15s\n",
      "10800:\tlearn: 6.6971154\ttest: 7.7397475\tbest: 7.7397475 (10800)\ttotal: 4m 56s\tremaining: 4m 12s\n",
      "10900:\tlearn: 6.6879791\ttest: 7.7358069\tbest: 7.7358069 (10900)\ttotal: 4m 59s\tremaining: 4m 10s\n",
      "11000:\tlearn: 6.6789810\ttest: 7.7321106\tbest: 7.7321106 (11000)\ttotal: 5m 2s\tremaining: 4m 7s\n",
      "11100:\tlearn: 6.6701586\ttest: 7.7284142\tbest: 7.7284142 (11100)\ttotal: 5m 4s\tremaining: 4m 4s\n",
      "11200:\tlearn: 6.6610018\ttest: 7.7245915\tbest: 7.7245915 (11200)\ttotal: 5m 7s\tremaining: 4m 1s\n",
      "11300:\tlearn: 6.6516600\ttest: 7.7206248\tbest: 7.7206248 (11300)\ttotal: 5m 10s\tremaining: 3m 58s\n",
      "11400:\tlearn: 6.6429843\ttest: 7.7168337\tbest: 7.7168337 (11400)\ttotal: 5m 12s\tremaining: 3m 55s\n",
      "11500:\tlearn: 6.6337439\ttest: 7.7133781\tbest: 7.7133781 (11500)\ttotal: 5m 15s\tremaining: 3m 53s\n",
      "11600:\tlearn: 6.6255066\ttest: 7.7103850\tbest: 7.7103850 (11600)\ttotal: 5m 18s\tremaining: 3m 50s\n",
      "11700:\tlearn: 6.6168407\ttest: 7.7069365\tbest: 7.7069365 (11700)\ttotal: 5m 21s\tremaining: 3m 47s\n",
      "11800:\tlearn: 6.6083942\ttest: 7.7033096\tbest: 7.7033096 (11800)\ttotal: 5m 24s\tremaining: 3m 45s\n",
      "11900:\tlearn: 6.5995852\ttest: 7.6996979\tbest: 7.6996979 (11900)\ttotal: 5m 26s\tremaining: 3m 42s\n",
      "12000:\tlearn: 6.5912674\ttest: 7.6963187\tbest: 7.6963187 (12000)\ttotal: 5m 29s\tremaining: 3m 39s\n",
      "12100:\tlearn: 6.5830968\ttest: 7.6924623\tbest: 7.6924623 (12100)\ttotal: 5m 32s\tremaining: 3m 37s\n",
      "12200:\tlearn: 6.5743313\ttest: 7.6888068\tbest: 7.6888068 (12200)\ttotal: 5m 35s\tremaining: 3m 34s\n",
      "12300:\tlearn: 6.5659202\ttest: 7.6855195\tbest: 7.6855195 (12300)\ttotal: 5m 37s\tremaining: 3m 31s\n",
      "12400:\tlearn: 6.5580376\ttest: 7.6821991\tbest: 7.6821895 (12399)\ttotal: 5m 40s\tremaining: 3m 28s\n",
      "12500:\tlearn: 6.5495584\ttest: 7.6788671\tbest: 7.6788671 (12500)\ttotal: 5m 43s\tremaining: 3m 25s\n",
      "12600:\tlearn: 6.5410288\ttest: 7.6749157\tbest: 7.6748829 (12597)\ttotal: 5m 45s\tremaining: 3m 22s\n",
      "12700:\tlearn: 6.5331894\ttest: 7.6712201\tbest: 7.6712201 (12700)\ttotal: 5m 48s\tremaining: 3m 20s\n",
      "12800:\tlearn: 6.5246729\ttest: 7.6676461\tbest: 7.6676461 (12800)\ttotal: 5m 51s\tremaining: 3m 17s\n",
      "12900:\tlearn: 6.5166157\ttest: 7.6643749\tbest: 7.6643749 (12900)\ttotal: 5m 53s\tremaining: 3m 14s\n",
      "13000:\tlearn: 6.5083521\ttest: 7.6608970\tbest: 7.6608970 (13000)\ttotal: 5m 56s\tremaining: 3m 11s\n",
      "13100:\tlearn: 6.5006235\ttest: 7.6573697\tbest: 7.6573697 (13100)\ttotal: 5m 59s\tremaining: 3m 9s\n",
      "13200:\tlearn: 6.4925093\ttest: 7.6543572\tbest: 7.6543264 (13199)\ttotal: 6m 2s\tremaining: 3m 6s\n",
      "13300:\tlearn: 6.4844618\ttest: 7.6513384\tbest: 7.6513384 (13300)\ttotal: 6m 5s\tremaining: 3m 4s\n",
      "13400:\tlearn: 6.4763269\ttest: 7.6477076\tbest: 7.6477076 (13400)\ttotal: 6m 10s\tremaining: 3m 2s\n",
      "13500:\tlearn: 6.4684482\ttest: 7.6445233\tbest: 7.6445233 (13500)\ttotal: 6m 17s\tremaining: 3m 1s\n",
      "13600:\tlearn: 6.4604581\ttest: 7.6412876\tbest: 7.6412876 (13600)\ttotal: 6m 24s\tremaining: 3m\n",
      "13700:\tlearn: 6.4525838\ttest: 7.6379260\tbest: 7.6379260 (13700)\ttotal: 6m 29s\tremaining: 2m 58s\n",
      "13800:\tlearn: 6.4447495\ttest: 7.6341342\tbest: 7.6341342 (13800)\ttotal: 6m 33s\tremaining: 2m 56s\n",
      "13900:\tlearn: 6.4372146\ttest: 7.6309855\tbest: 7.6309855 (13900)\ttotal: 6m 38s\tremaining: 2m 54s\n",
      "14000:\tlearn: 6.4295873\ttest: 7.6277010\tbest: 7.6277010 (14000)\ttotal: 6m 43s\tremaining: 2m 52s\n",
      "14100:\tlearn: 6.4218670\ttest: 7.6249940\tbest: 7.6249940 (14100)\ttotal: 6m 48s\tremaining: 2m 50s\n",
      "14200:\tlearn: 6.4139746\ttest: 7.6216072\tbest: 7.6216072 (14200)\ttotal: 6m 53s\tremaining: 2m 48s\n",
      "14300:\tlearn: 6.4064113\ttest: 7.6184767\tbest: 7.6184767 (14300)\ttotal: 6m 58s\tremaining: 2m 46s\n",
      "14400:\tlearn: 6.3984412\ttest: 7.6150797\tbest: 7.6150797 (14400)\ttotal: 7m 2s\tremaining: 2m 44s\n",
      "14500:\tlearn: 6.3909364\ttest: 7.6124381\tbest: 7.6124381 (14500)\ttotal: 7m 7s\tremaining: 2m 42s\n",
      "14600:\tlearn: 6.3835661\ttest: 7.6097652\tbest: 7.6097528 (14599)\ttotal: 7m 12s\tremaining: 2m 39s\n",
      "14700:\tlearn: 6.3759205\ttest: 7.6067509\tbest: 7.6067509 (14700)\ttotal: 7m 17s\tremaining: 2m 37s\n",
      "14800:\tlearn: 6.3686917\ttest: 7.6039998\tbest: 7.6039794 (14797)\ttotal: 7m 22s\tremaining: 2m 35s\n",
      "14900:\tlearn: 6.3612817\ttest: 7.6006879\tbest: 7.6006879 (14900)\ttotal: 7m 27s\tremaining: 2m 33s\n",
      "15000:\tlearn: 6.3539705\ttest: 7.5977628\tbest: 7.5977628 (15000)\ttotal: 7m 31s\tremaining: 2m 30s\n",
      "15100:\tlearn: 6.3468059\ttest: 7.5947038\tbest: 7.5947038 (15100)\ttotal: 7m 36s\tremaining: 2m 28s\n",
      "15200:\tlearn: 6.3390297\ttest: 7.5920567\tbest: 7.5920567 (15200)\ttotal: 7m 41s\tremaining: 2m 25s\n",
      "15300:\tlearn: 6.3318943\ttest: 7.5893419\tbest: 7.5893419 (15300)\ttotal: 7m 45s\tremaining: 2m 23s\n",
      "15400:\tlearn: 6.3250260\ttest: 7.5865255\tbest: 7.5865255 (15400)\ttotal: 7m 50s\tremaining: 2m 20s\n",
      "15500:\tlearn: 6.3179063\ttest: 7.5831685\tbest: 7.5831685 (15500)\ttotal: 7m 54s\tremaining: 2m 17s\n",
      "15600:\tlearn: 6.3113243\ttest: 7.5805890\tbest: 7.5805890 (15600)\ttotal: 7m 59s\tremaining: 2m 15s\n",
      "15700:\tlearn: 6.3042447\ttest: 7.5780016\tbest: 7.5779980 (15699)\ttotal: 8m 4s\tremaining: 2m 12s\n",
      "15800:\tlearn: 6.2972263\ttest: 7.5754482\tbest: 7.5754482 (15800)\ttotal: 8m 8s\tremaining: 2m 9s\n",
      "15900:\tlearn: 6.2901291\ttest: 7.5727672\tbest: 7.5727672 (15900)\ttotal: 8m 13s\tremaining: 2m 7s\n",
      "16000:\tlearn: 6.2830240\ttest: 7.5696445\tbest: 7.5696445 (16000)\ttotal: 8m 18s\tremaining: 2m 4s\n",
      "16100:\tlearn: 6.2759787\ttest: 7.5669916\tbest: 7.5669916 (16100)\ttotal: 8m 22s\tremaining: 2m 1s\n",
      "16200:\tlearn: 6.2689502\ttest: 7.5643735\tbest: 7.5643664 (16198)\ttotal: 8m 27s\tremaining: 1m 59s\n",
      "16300:\tlearn: 6.2622070\ttest: 7.5617676\tbest: 7.5617676 (16300)\ttotal: 8m 32s\tremaining: 1m 56s\n",
      "16400:\tlearn: 6.2554417\ttest: 7.5592153\tbest: 7.5592153 (16400)\ttotal: 8m 36s\tremaining: 1m 53s\n",
      "16500:\tlearn: 6.2485036\ttest: 7.5564590\tbest: 7.5564590 (16500)\ttotal: 8m 41s\tremaining: 1m 50s\n",
      "16600:\tlearn: 6.2411545\ttest: 7.5532039\tbest: 7.5532039 (16600)\ttotal: 8m 46s\tremaining: 1m 47s\n",
      "16700:\tlearn: 6.2341666\ttest: 7.5507110\tbest: 7.5507110 (16700)\ttotal: 8m 50s\tremaining: 1m 44s\n",
      "16800:\tlearn: 6.2275266\ttest: 7.5480464\tbest: 7.5480464 (16800)\ttotal: 8m 55s\tremaining: 1m 41s\n",
      "16900:\tlearn: 6.2206335\ttest: 7.5453792\tbest: 7.5453633 (16899)\ttotal: 9m\tremaining: 1m 39s\n",
      "17000:\tlearn: 6.2134783\ttest: 7.5424762\tbest: 7.5424524 (16998)\ttotal: 9m 4s\tremaining: 1m 36s\n",
      "17100:\tlearn: 6.2065508\ttest: 7.5399298\tbest: 7.5399097 (17097)\ttotal: 9m 9s\tremaining: 1m 33s\n",
      "17200:\tlearn: 6.1997017\ttest: 7.5374446\tbest: 7.5374335 (17199)\ttotal: 9m 14s\tremaining: 1m 30s\n",
      "17300:\tlearn: 6.1931175\ttest: 7.5350043\tbest: 7.5350043 (17300)\ttotal: 9m 18s\tremaining: 1m 27s\n",
      "17400:\tlearn: 6.1867074\ttest: 7.5328064\tbest: 7.5328064 (17400)\ttotal: 9m 23s\tremaining: 1m 24s\n",
      "17500:\tlearn: 6.1803056\ttest: 7.5303043\tbest: 7.5302775 (17499)\ttotal: 9m 28s\tremaining: 1m 21s\n",
      "17600:\tlearn: 6.1739900\ttest: 7.5281488\tbest: 7.5281488 (17600)\ttotal: 9m 31s\tremaining: 1m 17s\n",
      "17700:\tlearn: 6.1673795\ttest: 7.5257324\tbest: 7.5257324 (17700)\ttotal: 9m 33s\tremaining: 1m 14s\n",
      "17800:\tlearn: 6.1609289\ttest: 7.5228930\tbest: 7.5228930 (17800)\ttotal: 9m 36s\tremaining: 1m 11s\n",
      "17900:\tlearn: 6.1544506\ttest: 7.5207705\tbest: 7.5207705 (17900)\ttotal: 9m 39s\tremaining: 1m 7s\n",
      "18000:\tlearn: 6.1486380\ttest: 7.5183315\tbest: 7.5183315 (18000)\ttotal: 9m 41s\tremaining: 1m 4s\n",
      "18100:\tlearn: 6.1420571\ttest: 7.5157905\tbest: 7.5157755 (18099)\ttotal: 9m 44s\tremaining: 1m 1s\n",
      "18200:\tlearn: 6.1355377\ttest: 7.5131127\tbest: 7.5130879 (18199)\ttotal: 9m 47s\tremaining: 58s\n",
      "18300:\tlearn: 6.1288588\ttest: 7.5101545\tbest: 7.5101545 (18300)\ttotal: 9m 49s\tremaining: 54.8s\n",
      "18400:\tlearn: 6.1223174\ttest: 7.5078712\tbest: 7.5078712 (18400)\ttotal: 9m 52s\tremaining: 51.5s\n",
      "18500:\tlearn: 6.1159022\ttest: 7.5056172\tbest: 7.5056172 (18500)\ttotal: 9m 55s\tremaining: 48.2s\n",
      "18600:\tlearn: 6.1090959\ttest: 7.5030189\tbest: 7.5030189 (18600)\ttotal: 9m 58s\tremaining: 45s\n",
      "18700:\tlearn: 6.1026281\ttest: 7.5004874\tbest: 7.5004677 (18699)\ttotal: 10m\tremaining: 41.7s\n",
      "18800:\tlearn: 6.0958643\ttest: 7.4977844\tbest: 7.4977844 (18800)\ttotal: 10m 3s\tremaining: 38.5s\n",
      "18900:\tlearn: 6.0894452\ttest: 7.4952767\tbest: 7.4952767 (18900)\ttotal: 10m 5s\tremaining: 35.2s\n",
      "19000:\tlearn: 6.0827068\ttest: 7.4930561\tbest: 7.4930561 (19000)\ttotal: 10m 8s\tremaining: 32s\n",
      "19100:\tlearn: 6.0762408\ttest: 7.4904079\tbest: 7.4904079 (19100)\ttotal: 10m 10s\tremaining: 28.7s\n",
      "19200:\tlearn: 6.0703266\ttest: 7.4884542\tbest: 7.4884457 (19199)\ttotal: 10m 13s\tremaining: 25.5s\n",
      "19300:\tlearn: 6.0641181\ttest: 7.4862385\tbest: 7.4862385 (19300)\ttotal: 10m 15s\tremaining: 22.3s\n",
      "19400:\tlearn: 6.0578460\ttest: 7.4838703\tbest: 7.4838703 (19400)\ttotal: 10m 18s\tremaining: 19.1s\n",
      "19500:\tlearn: 6.0516272\ttest: 7.4812745\tbest: 7.4812745 (19500)\ttotal: 10m 21s\tremaining: 15.9s\n",
      "19600:\tlearn: 6.0451048\ttest: 7.4791896\tbest: 7.4791896 (19600)\ttotal: 10m 23s\tremaining: 12.7s\n",
      "19700:\tlearn: 6.0388583\ttest: 7.4763653\tbest: 7.4763653 (19700)\ttotal: 10m 26s\tremaining: 9.5s\n",
      "19800:\tlearn: 6.0326106\ttest: 7.4741854\tbest: 7.4741854 (19800)\ttotal: 10m 28s\tremaining: 6.32s\n",
      "19900:\tlearn: 6.0265920\ttest: 7.4720763\tbest: 7.4720763 (19900)\ttotal: 10m 31s\tremaining: 3.14s\n",
      "19999:\tlearn: 6.0205643\ttest: 7.4694030\tbest: 7.4694019 (19998)\ttotal: 10m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.469401897\n",
      "bestIteration = 19998\n",
      "\n",
      "Shrink model to first 19999 iterations.\n",
      "Root Mean Squared Error: 7.469401900510753\n",
      "Mean Squared Error (MSE): 55.79196475135364\n",
      "Mean Absolute Error (MAE): 5.112194227022111\n",
      "R-squared (R^2): 0.3073726476490981\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = cb.CatBoostRegressor(\n",
    "    iterations=20000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=200, \n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4394809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 8.9256845\ttest: 8.9938600\tbest: 8.9938600 (0)\ttotal: 21.1ms\tremaining: 5m 15s\n",
      "100:\tlearn: 8.7973636\ttest: 8.8745814\tbest: 8.8745814 (100)\ttotal: 1.61s\tremaining: 3m 58s\n",
      "200:\tlearn: 8.7528215\ttest: 8.8451261\tbest: 8.8451261 (200)\ttotal: 3.13s\tremaining: 3m 50s\n",
      "300:\tlearn: 8.7197124\ttest: 8.8230832\tbest: 8.8230832 (300)\ttotal: 4.67s\tremaining: 3m 48s\n",
      "400:\tlearn: 8.6951105\ttest: 8.8052595\tbest: 8.8052595 (400)\ttotal: 6.19s\tremaining: 3m 45s\n",
      "500:\tlearn: 8.6751524\ttest: 8.7951475\tbest: 8.7951475 (500)\ttotal: 7.68s\tremaining: 3m 42s\n",
      "600:\tlearn: 8.6578284\ttest: 8.7846800\tbest: 8.7846800 (600)\ttotal: 9.34s\tremaining: 3m 43s\n",
      "700:\tlearn: 8.6405027\ttest: 8.7745495\tbest: 8.7745495 (700)\ttotal: 10.9s\tremaining: 3m 42s\n",
      "800:\tlearn: 8.6264825\ttest: 8.7684566\tbest: 8.7684566 (800)\ttotal: 12.5s\tremaining: 3m 42s\n",
      "900:\tlearn: 8.6105975\ttest: 8.7619951\tbest: 8.7619951 (900)\ttotal: 14.5s\tremaining: 3m 47s\n",
      "1000:\tlearn: 8.5967064\ttest: 8.7521975\tbest: 8.7521973 (999)\ttotal: 17.4s\tremaining: 4m 2s\n",
      "1100:\tlearn: 8.5827056\ttest: 8.7441399\tbest: 8.7441399 (1100)\ttotal: 20.2s\tremaining: 4m 14s\n",
      "1200:\tlearn: 8.5702144\ttest: 8.7371357\tbest: 8.7371314 (1199)\ttotal: 23s\tremaining: 4m 24s\n",
      "1300:\tlearn: 8.5577997\ttest: 8.7297190\tbest: 8.7297190 (1300)\ttotal: 25.9s\tremaining: 4m 33s\n",
      "1400:\tlearn: 8.5456395\ttest: 8.7227606\tbest: 8.7227606 (1400)\ttotal: 28.8s\tremaining: 4m 39s\n",
      "1500:\tlearn: 8.5350311\ttest: 8.7163873\tbest: 8.7162582 (1496)\ttotal: 31.5s\tremaining: 4m 43s\n",
      "1600:\tlearn: 8.5244803\ttest: 8.7102229\tbest: 8.7102229 (1600)\ttotal: 34.4s\tremaining: 4m 47s\n",
      "1700:\tlearn: 8.5145503\ttest: 8.7049868\tbest: 8.7049868 (1700)\ttotal: 37.1s\tremaining: 4m 50s\n",
      "1800:\tlearn: 8.5040924\ttest: 8.6982277\tbest: 8.6982277 (1800)\ttotal: 39.8s\tremaining: 4m 52s\n",
      "1900:\tlearn: 8.4941351\ttest: 8.6918337\tbest: 8.6918227 (1899)\ttotal: 42.5s\tremaining: 4m 53s\n",
      "2000:\tlearn: 8.4842075\ttest: 8.6860111\tbest: 8.6858937 (1999)\ttotal: 45.4s\tremaining: 4m 54s\n",
      "2100:\tlearn: 8.4742840\ttest: 8.6807196\tbest: 8.6807196 (2100)\ttotal: 48.1s\tremaining: 4m 55s\n",
      "2200:\tlearn: 8.4657242\ttest: 8.6755985\tbest: 8.6755800 (2199)\ttotal: 50.8s\tremaining: 4m 55s\n",
      "2300:\tlearn: 8.4584958\ttest: 8.6721551\tbest: 8.6721207 (2299)\ttotal: 53.6s\tremaining: 4m 55s\n",
      "2400:\tlearn: 8.4496323\ttest: 8.6664228\tbest: 8.6663251 (2399)\ttotal: 56.3s\tremaining: 4m 55s\n",
      "2500:\tlearn: 8.4405481\ttest: 8.6599811\tbest: 8.6599811 (2500)\ttotal: 59.1s\tremaining: 4m 55s\n",
      "2600:\tlearn: 8.4333920\ttest: 8.6565173\tbest: 8.6565173 (2600)\ttotal: 1m 1s\tremaining: 4m 54s\n",
      "2700:\tlearn: 8.4254094\ttest: 8.6519242\tbest: 8.6519242 (2700)\ttotal: 1m 4s\tremaining: 4m 54s\n",
      "2800:\tlearn: 8.4177179\ttest: 8.6471506\tbest: 8.6471506 (2800)\ttotal: 1m 7s\tremaining: 4m 53s\n",
      "2900:\tlearn: 8.4103678\ttest: 8.6420614\tbest: 8.6420614 (2900)\ttotal: 1m 10s\tremaining: 4m 52s\n",
      "3000:\tlearn: 8.4032917\ttest: 8.6374806\tbest: 8.6374806 (3000)\ttotal: 1m 12s\tremaining: 4m 50s\n",
      "3100:\tlearn: 8.3956833\ttest: 8.6329680\tbest: 8.6329680 (3100)\ttotal: 1m 15s\tremaining: 4m 49s\n",
      "3200:\tlearn: 8.3888820\ttest: 8.6302168\tbest: 8.6302168 (3200)\ttotal: 1m 18s\tremaining: 4m 48s\n",
      "3300:\tlearn: 8.3821377\ttest: 8.6274115\tbest: 8.6273886 (3298)\ttotal: 1m 20s\tremaining: 4m 47s\n",
      "3400:\tlearn: 8.3754674\ttest: 8.6244061\tbest: 8.6244061 (3400)\ttotal: 1m 23s\tremaining: 4m 45s\n",
      "3500:\tlearn: 8.3690340\ttest: 8.6211116\tbest: 8.6211116 (3500)\ttotal: 1m 26s\tremaining: 4m 43s\n",
      "3600:\tlearn: 8.3627585\ttest: 8.6174587\tbest: 8.6174587 (3600)\ttotal: 1m 29s\tremaining: 4m 42s\n",
      "3700:\tlearn: 8.3555739\ttest: 8.6145448\tbest: 8.6145448 (3700)\ttotal: 1m 31s\tremaining: 4m 40s\n",
      "3800:\tlearn: 8.3488814\ttest: 8.6114471\tbest: 8.6113691 (3797)\ttotal: 1m 34s\tremaining: 4m 38s\n",
      "3900:\tlearn: 8.3426749\ttest: 8.6085459\tbest: 8.6085459 (3900)\ttotal: 1m 37s\tremaining: 4m 36s\n",
      "4000:\tlearn: 8.3364560\ttest: 8.6055923\tbest: 8.6055923 (4000)\ttotal: 1m 40s\tremaining: 4m 34s\n",
      "4100:\tlearn: 8.3301469\ttest: 8.6025508\tbest: 8.6025508 (4100)\ttotal: 1m 42s\tremaining: 4m 33s\n",
      "4200:\tlearn: 8.3242336\ttest: 8.5999760\tbest: 8.5998528 (4198)\ttotal: 1m 45s\tremaining: 4m 31s\n",
      "4300:\tlearn: 8.3187400\ttest: 8.5972095\tbest: 8.5971526 (4292)\ttotal: 1m 48s\tremaining: 4m 29s\n",
      "4400:\tlearn: 8.3129209\ttest: 8.5946023\tbest: 8.5945745 (4399)\ttotal: 1m 50s\tremaining: 4m 27s\n",
      "4500:\tlearn: 8.3072009\ttest: 8.5921393\tbest: 8.5921393 (4500)\ttotal: 1m 53s\tremaining: 4m 25s\n",
      "4600:\tlearn: 8.3018455\ttest: 8.5887318\tbest: 8.5887318 (4600)\ttotal: 1m 56s\tremaining: 4m 23s\n",
      "4700:\tlearn: 8.2964051\ttest: 8.5856339\tbest: 8.5856339 (4700)\ttotal: 1m 59s\tremaining: 4m 20s\n",
      "4800:\tlearn: 8.2912839\ttest: 8.5835129\tbest: 8.5834043 (4793)\ttotal: 2m 1s\tremaining: 4m 18s\n",
      "4900:\tlearn: 8.2858830\ttest: 8.5814478\tbest: 8.5814478 (4900)\ttotal: 2m 4s\tremaining: 4m 16s\n",
      "5000:\tlearn: 8.2806005\ttest: 8.5790872\tbest: 8.5790872 (5000)\ttotal: 2m 7s\tremaining: 4m 14s\n",
      "5100:\tlearn: 8.2750960\ttest: 8.5770180\tbest: 8.5768869 (5098)\ttotal: 2m 10s\tremaining: 4m 12s\n",
      "5200:\tlearn: 8.2699798\ttest: 8.5739203\tbest: 8.5739203 (5200)\ttotal: 2m 12s\tremaining: 4m 10s\n",
      "5300:\tlearn: 8.2648712\ttest: 8.5712356\tbest: 8.5712356 (5300)\ttotal: 2m 15s\tremaining: 4m 8s\n",
      "5400:\tlearn: 8.2600091\ttest: 8.5685789\tbest: 8.5685779 (5399)\ttotal: 2m 18s\tremaining: 4m 6s\n",
      "5500:\tlearn: 8.2549422\ttest: 8.5655568\tbest: 8.5655568 (5500)\ttotal: 2m 21s\tremaining: 4m 4s\n",
      "5600:\tlearn: 8.2492396\ttest: 8.5625380\tbest: 8.5625380 (5600)\ttotal: 2m 24s\tremaining: 4m 2s\n",
      "5700:\tlearn: 8.2441517\ttest: 8.5592575\tbest: 8.5592575 (5700)\ttotal: 2m 27s\tremaining: 3m 59s\n",
      "5800:\tlearn: 8.2395592\ttest: 8.5572368\tbest: 8.5572308 (5797)\ttotal: 2m 29s\tremaining: 3m 57s\n",
      "5900:\tlearn: 8.2346912\ttest: 8.5544491\tbest: 8.5544491 (5900)\ttotal: 2m 32s\tremaining: 3m 55s\n",
      "6000:\tlearn: 8.2298100\ttest: 8.5530222\tbest: 8.5530222 (6000)\ttotal: 2m 35s\tremaining: 3m 53s\n",
      "6100:\tlearn: 8.2248049\ttest: 8.5505552\tbest: 8.5505552 (6100)\ttotal: 2m 38s\tremaining: 3m 51s\n",
      "6200:\tlearn: 8.2203336\ttest: 8.5490331\tbest: 8.5489583 (6198)\ttotal: 2m 41s\tremaining: 3m 49s\n",
      "6300:\tlearn: 8.2156113\ttest: 8.5457864\tbest: 8.5457864 (6300)\ttotal: 2m 44s\tremaining: 3m 46s\n",
      "6400:\tlearn: 8.2108159\ttest: 8.5427737\tbest: 8.5427737 (6400)\ttotal: 2m 47s\tremaining: 3m 44s\n",
      "6500:\tlearn: 8.2068046\ttest: 8.5412651\tbest: 8.5412437 (6494)\ttotal: 2m 49s\tremaining: 3m 42s\n",
      "6600:\tlearn: 8.2023290\ttest: 8.5383022\tbest: 8.5383022 (6600)\ttotal: 2m 52s\tremaining: 3m 39s\n",
      "6700:\tlearn: 8.1977519\ttest: 8.5356068\tbest: 8.5356068 (6700)\ttotal: 2m 55s\tremaining: 3m 37s\n",
      "6800:\tlearn: 8.1934420\ttest: 8.5337592\tbest: 8.5336723 (6798)\ttotal: 2m 58s\tremaining: 3m 35s\n",
      "6900:\tlearn: 8.1888638\ttest: 8.5311126\tbest: 8.5310910 (6898)\ttotal: 3m 1s\tremaining: 3m 32s\n",
      "7000:\tlearn: 8.1843506\ttest: 8.5294908\tbest: 8.5294908 (7000)\ttotal: 3m 4s\tremaining: 3m 30s\n",
      "7100:\tlearn: 8.1801153\ttest: 8.5269917\tbest: 8.5269827 (7099)\ttotal: 3m 6s\tremaining: 3m 27s\n",
      "7200:\tlearn: 8.1760612\ttest: 8.5246578\tbest: 8.5245563 (7199)\ttotal: 3m 9s\tremaining: 3m 25s\n",
      "7300:\tlearn: 8.1717318\ttest: 8.5227368\tbest: 8.5227368 (7300)\ttotal: 3m 12s\tremaining: 3m 23s\n",
      "7400:\tlearn: 8.1675013\ttest: 8.5204880\tbest: 8.5203175 (7396)\ttotal: 3m 15s\tremaining: 3m 20s\n",
      "7500:\tlearn: 8.1633551\ttest: 8.5187900\tbest: 8.5187161 (7497)\ttotal: 3m 18s\tremaining: 3m 18s\n",
      "7600:\tlearn: 8.1592519\ttest: 8.5170668\tbest: 8.5170193 (7591)\ttotal: 3m 21s\tremaining: 3m 15s\n",
      "7700:\tlearn: 8.1552732\ttest: 8.5152072\tbest: 8.5152072 (7700)\ttotal: 3m 23s\tremaining: 3m 13s\n",
      "7800:\tlearn: 8.1509256\ttest: 8.5124170\tbest: 8.5124170 (7800)\ttotal: 3m 26s\tremaining: 3m 10s\n",
      "7900:\tlearn: 8.1469139\ttest: 8.5109087\tbest: 8.5108722 (7898)\ttotal: 3m 29s\tremaining: 3m 8s\n",
      "8000:\tlearn: 8.1428172\ttest: 8.5089013\tbest: 8.5088959 (7996)\ttotal: 3m 32s\tremaining: 3m 5s\n",
      "8100:\tlearn: 8.1389766\ttest: 8.5072443\tbest: 8.5072376 (8099)\ttotal: 3m 35s\tremaining: 3m 3s\n",
      "8200:\tlearn: 8.1351061\ttest: 8.5048048\tbest: 8.5048048 (8200)\ttotal: 3m 37s\tremaining: 3m\n",
      "8300:\tlearn: 8.1310902\ttest: 8.5028762\tbest: 8.5028762 (8300)\ttotal: 3m 40s\tremaining: 2m 57s\n",
      "8400:\tlearn: 8.1273763\ttest: 8.5014503\tbest: 8.5014503 (8400)\ttotal: 3m 43s\tremaining: 2m 55s\n",
      "8500:\tlearn: 8.1235496\ttest: 8.4992482\tbest: 8.4992351 (8498)\ttotal: 3m 46s\tremaining: 2m 52s\n",
      "8600:\tlearn: 8.1199202\ttest: 8.4970420\tbest: 8.4970256 (8598)\ttotal: 3m 48s\tremaining: 2m 50s\n",
      "8700:\tlearn: 8.1163583\ttest: 8.4957534\tbest: 8.4957512 (8698)\ttotal: 3m 51s\tremaining: 2m 47s\n",
      "8800:\tlearn: 8.1127272\ttest: 8.4943254\tbest: 8.4943254 (8800)\ttotal: 3m 54s\tremaining: 2m 45s\n",
      "8900:\tlearn: 8.1088466\ttest: 8.4911860\tbest: 8.4911860 (8900)\ttotal: 3m 57s\tremaining: 2m 42s\n",
      "9000:\tlearn: 8.1051563\ttest: 8.4904929\tbest: 8.4904929 (9000)\ttotal: 4m\tremaining: 2m 40s\n",
      "9100:\tlearn: 8.1014970\ttest: 8.4884236\tbest: 8.4884236 (9100)\ttotal: 4m 3s\tremaining: 2m 37s\n",
      "9200:\tlearn: 8.0979848\ttest: 8.4863496\tbest: 8.4863202 (9199)\ttotal: 4m 5s\tremaining: 2m 35s\n",
      "9300:\tlearn: 8.0942946\ttest: 8.4849559\tbest: 8.4849559 (9300)\ttotal: 4m 8s\tremaining: 2m 32s\n",
      "9400:\tlearn: 8.0905582\ttest: 8.4834915\tbest: 8.4834915 (9400)\ttotal: 4m 11s\tremaining: 2m 29s\n",
      "9500:\tlearn: 8.0870328\ttest: 8.4822946\tbest: 8.4821387 (9487)\ttotal: 4m 14s\tremaining: 2m 27s\n",
      "9600:\tlearn: 8.0836963\ttest: 8.4803837\tbest: 8.4803511 (9599)\ttotal: 4m 17s\tremaining: 2m 24s\n",
      "9700:\tlearn: 8.0803390\ttest: 8.4787800\tbest: 8.4787800 (9700)\ttotal: 4m 20s\tremaining: 2m 22s\n",
      "9800:\tlearn: 8.0768505\ttest: 8.4772443\tbest: 8.4771578 (9793)\ttotal: 4m 22s\tremaining: 2m 19s\n",
      "9900:\tlearn: 8.0735356\ttest: 8.4757561\tbest: 8.4756389 (9887)\ttotal: 4m 25s\tremaining: 2m 16s\n",
      "10000:\tlearn: 8.0700703\ttest: 8.4744959\tbest: 8.4744959 (10000)\ttotal: 4m 28s\tremaining: 2m 14s\n",
      "10100:\tlearn: 8.0665144\ttest: 8.4730779\tbest: 8.4730555 (10099)\ttotal: 4m 31s\tremaining: 2m 11s\n",
      "10200:\tlearn: 8.0629744\ttest: 8.4714379\tbest: 8.4714276 (10199)\ttotal: 4m 34s\tremaining: 2m 9s\n",
      "10300:\tlearn: 8.0595198\ttest: 8.4693419\tbest: 8.4693106 (10299)\ttotal: 4m 37s\tremaining: 2m 6s\n",
      "10400:\tlearn: 8.0562082\ttest: 8.4681996\tbest: 8.4681996 (10400)\ttotal: 4m 39s\tremaining: 2m 3s\n",
      "10500:\tlearn: 8.0529743\ttest: 8.4663671\tbest: 8.4663595 (10498)\ttotal: 4m 42s\tremaining: 2m 1s\n",
      "10600:\tlearn: 8.0497751\ttest: 8.4650343\tbest: 8.4649757 (10597)\ttotal: 4m 45s\tremaining: 1m 58s\n",
      "10700:\tlearn: 8.0463073\ttest: 8.4636806\tbest: 8.4636727 (10699)\ttotal: 4m 48s\tremaining: 1m 55s\n",
      "10800:\tlearn: 8.0431710\ttest: 8.4627743\tbest: 8.4627621 (10796)\ttotal: 4m 51s\tremaining: 1m 53s\n",
      "10900:\tlearn: 8.0398027\ttest: 8.4612568\tbest: 8.4612568 (10900)\ttotal: 4m 53s\tremaining: 1m 50s\n",
      "11000:\tlearn: 8.0365197\ttest: 8.4599599\tbest: 8.4599599 (11000)\ttotal: 4m 56s\tremaining: 1m 47s\n",
      "11100:\tlearn: 8.0332934\ttest: 8.4585489\tbest: 8.4585489 (11100)\ttotal: 4m 59s\tremaining: 1m 45s\n",
      "11200:\tlearn: 8.0299966\ttest: 8.4567727\tbest: 8.4567466 (11199)\ttotal: 5m 2s\tremaining: 1m 42s\n",
      "11300:\tlearn: 8.0268408\ttest: 8.4555611\tbest: 8.4554669 (11297)\ttotal: 5m 5s\tremaining: 1m 39s\n",
      "11400:\tlearn: 8.0237365\ttest: 8.4545536\tbest: 8.4545536 (11400)\ttotal: 5m 7s\tremaining: 1m 37s\n",
      "11500:\tlearn: 8.0204282\ttest: 8.4537532\tbest: 8.4537532 (11500)\ttotal: 5m 10s\tremaining: 1m 34s\n",
      "11600:\tlearn: 8.0172370\ttest: 8.4519001\tbest: 8.4519001 (11600)\ttotal: 5m 13s\tremaining: 1m 31s\n",
      "11700:\tlearn: 8.0142339\ttest: 8.4506412\tbest: 8.4506412 (11700)\ttotal: 5m 16s\tremaining: 1m 29s\n",
      "11800:\tlearn: 8.0112077\ttest: 8.4495297\tbest: 8.4495297 (11800)\ttotal: 5m 19s\tremaining: 1m 26s\n",
      "11900:\tlearn: 8.0081316\ttest: 8.4480604\tbest: 8.4480308 (11898)\ttotal: 5m 21s\tremaining: 1m 23s\n",
      "12000:\tlearn: 8.0048987\ttest: 8.4460602\tbest: 8.4460580 (11999)\ttotal: 5m 24s\tremaining: 1m 21s\n",
      "12100:\tlearn: 8.0016478\ttest: 8.4449415\tbest: 8.4449384 (12098)\ttotal: 5m 27s\tremaining: 1m 18s\n",
      "12200:\tlearn: 7.9985205\ttest: 8.4430602\tbest: 8.4430602 (12200)\ttotal: 5m 30s\tremaining: 1m 15s\n",
      "12300:\tlearn: 7.9954233\ttest: 8.4422419\tbest: 8.4422419 (12300)\ttotal: 5m 33s\tremaining: 1m 13s\n",
      "12400:\tlearn: 7.9925193\ttest: 8.4416077\tbest: 8.4416077 (12400)\ttotal: 5m 34s\tremaining: 1m 10s\n",
      "12500:\tlearn: 7.9892095\ttest: 8.4407184\tbest: 8.4407184 (12500)\ttotal: 5m 36s\tremaining: 1m 7s\n",
      "12600:\tlearn: 7.9861695\ttest: 8.4397656\tbest: 8.4397656 (12600)\ttotal: 5m 38s\tremaining: 1m 4s\n",
      "12700:\tlearn: 7.9831942\ttest: 8.4387526\tbest: 8.4387144 (12691)\ttotal: 5m 39s\tremaining: 1m 1s\n",
      "12800:\tlearn: 7.9804251\ttest: 8.4376746\tbest: 8.4376746 (12800)\ttotal: 5m 41s\tremaining: 58.6s\n",
      "12900:\tlearn: 7.9776307\ttest: 8.4370309\tbest: 8.4370309 (12900)\ttotal: 5m 42s\tremaining: 55.8s\n",
      "13000:\tlearn: 7.9747490\ttest: 8.4358512\tbest: 8.4358294 (12994)\ttotal: 5m 44s\tremaining: 52.9s\n",
      "13100:\tlearn: 7.9719694\ttest: 8.4345160\tbest: 8.4345158 (13099)\ttotal: 5m 46s\tremaining: 50.2s\n",
      "13200:\tlearn: 7.9690727\ttest: 8.4335100\tbest: 8.4334612 (13196)\ttotal: 5m 47s\tremaining: 47.4s\n",
      "13300:\tlearn: 7.9662544\ttest: 8.4324090\tbest: 8.4323459 (13299)\ttotal: 5m 49s\tremaining: 44.6s\n",
      "13400:\tlearn: 7.9632890\ttest: 8.4310688\tbest: 8.4310688 (13400)\ttotal: 5m 51s\tremaining: 41.9s\n",
      "13500:\tlearn: 7.9604760\ttest: 8.4302109\tbest: 8.4301661 (13496)\ttotal: 5m 52s\tremaining: 39.1s\n",
      "13600:\tlearn: 7.9577996\ttest: 8.4292171\tbest: 8.4292171 (13600)\ttotal: 5m 54s\tremaining: 36.4s\n",
      "13700:\tlearn: 7.9549430\ttest: 8.4280523\tbest: 8.4280523 (13700)\ttotal: 5m 55s\tremaining: 33.7s\n",
      "13800:\tlearn: 7.9520066\ttest: 8.4265515\tbest: 8.4264454 (13791)\ttotal: 5m 57s\tremaining: 31.1s\n",
      "13900:\tlearn: 7.9490570\ttest: 8.4252170\tbest: 8.4252170 (13900)\ttotal: 5m 58s\tremaining: 28.4s\n",
      "14000:\tlearn: 7.9460004\ttest: 8.4237773\tbest: 8.4237411 (13999)\ttotal: 6m\tremaining: 25.7s\n",
      "14100:\tlearn: 7.9429187\ttest: 8.4226136\tbest: 8.4225928 (14094)\ttotal: 6m 2s\tremaining: 23.1s\n",
      "14200:\tlearn: 7.9400807\ttest: 8.4216791\tbest: 8.4215441 (14195)\ttotal: 6m 3s\tremaining: 20.5s\n",
      "14300:\tlearn: 7.9373723\ttest: 8.4206345\tbest: 8.4206345 (14300)\ttotal: 6m 5s\tremaining: 17.9s\n",
      "14400:\tlearn: 7.9345806\ttest: 8.4195523\tbest: 8.4195523 (14400)\ttotal: 6m 7s\tremaining: 15.3s\n",
      "14500:\tlearn: 7.9318313\ttest: 8.4190132\tbest: 8.4188788 (14489)\ttotal: 6m 8s\tremaining: 12.7s\n",
      "14600:\tlearn: 7.9291213\ttest: 8.4180774\tbest: 8.4180707 (14599)\ttotal: 6m 10s\tremaining: 10.1s\n",
      "14700:\tlearn: 7.9264142\ttest: 8.4171439\tbest: 8.4171320 (14699)\ttotal: 6m 12s\tremaining: 7.57s\n",
      "14800:\tlearn: 7.9235285\ttest: 8.4157554\tbest: 8.4157554 (14800)\ttotal: 6m 13s\tremaining: 5.02s\n",
      "14900:\tlearn: 7.9208547\ttest: 8.4145036\tbest: 8.4145036 (14900)\ttotal: 6m 15s\tremaining: 2.49s\n",
      "14999:\tlearn: 7.9181492\ttest: 8.4135396\tbest: 8.4134610 (14996)\ttotal: 6m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 8.413460988\n",
      "bestIteration = 14996\n",
      "\n",
      "Shrink model to first 14997 iterations.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4400\n",
      "[LightGBM] [Info] Number of data points in the train set: 734002, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -0.088886\n",
      "0:\tlearn: 8.9256845\ttotal: 20ms\tremaining: 4m 59s\n",
      "100:\tlearn: 8.7973636\ttotal: 1.62s\tremaining: 3m 59s\n",
      "200:\tlearn: 8.7528215\ttotal: 3.18s\tremaining: 3m 54s\n",
      "300:\tlearn: 8.7197124\ttotal: 4.76s\tremaining: 3m 52s\n",
      "400:\tlearn: 8.6951105\ttotal: 6.37s\tremaining: 3m 51s\n",
      "500:\tlearn: 8.6751524\ttotal: 7.91s\tremaining: 3m 48s\n",
      "600:\tlearn: 8.6578284\ttotal: 9.47s\tremaining: 3m 46s\n",
      "700:\tlearn: 8.6405027\ttotal: 11.1s\tremaining: 3m 46s\n",
      "800:\tlearn: 8.6264825\ttotal: 12.7s\tremaining: 3m 44s\n",
      "900:\tlearn: 8.6105975\ttotal: 14.2s\tremaining: 3m 42s\n",
      "1000:\tlearn: 8.5967064\ttotal: 15.8s\tremaining: 3m 41s\n",
      "1100:\tlearn: 8.5827056\ttotal: 17.4s\tremaining: 3m 39s\n",
      "1200:\tlearn: 8.5702144\ttotal: 19s\tremaining: 3m 38s\n",
      "1300:\tlearn: 8.5577997\ttotal: 20.6s\tremaining: 3m 36s\n",
      "1400:\tlearn: 8.5456395\ttotal: 22.1s\tremaining: 3m 34s\n",
      "1500:\tlearn: 8.5350311\ttotal: 23.7s\tremaining: 3m 33s\n",
      "1600:\tlearn: 8.5244803\ttotal: 25.4s\tremaining: 3m 32s\n",
      "1700:\tlearn: 8.5145503\ttotal: 26.9s\tremaining: 3m 30s\n",
      "1800:\tlearn: 8.5040924\ttotal: 28.5s\tremaining: 3m 28s\n",
      "1900:\tlearn: 8.4941351\ttotal: 30.1s\tremaining: 3m 27s\n",
      "2000:\tlearn: 8.4842075\ttotal: 31.8s\tremaining: 3m 26s\n",
      "2100:\tlearn: 8.4742840\ttotal: 33.3s\tremaining: 3m 24s\n",
      "2200:\tlearn: 8.4657242\ttotal: 34.9s\tremaining: 3m 23s\n",
      "2300:\tlearn: 8.4584958\ttotal: 36.5s\tremaining: 3m 21s\n",
      "2400:\tlearn: 8.4496323\ttotal: 38.1s\tremaining: 3m 20s\n",
      "2500:\tlearn: 8.4405481\ttotal: 40s\tremaining: 3m 19s\n",
      "2600:\tlearn: 8.4333920\ttotal: 41.8s\tremaining: 3m 19s\n",
      "2700:\tlearn: 8.4254094\ttotal: 43.5s\tremaining: 3m 18s\n",
      "2800:\tlearn: 8.4177179\ttotal: 45.2s\tremaining: 3m 16s\n",
      "2900:\tlearn: 8.4103678\ttotal: 46.7s\tremaining: 3m 14s\n",
      "3000:\tlearn: 8.4032917\ttotal: 48.3s\tremaining: 3m 12s\n",
      "3100:\tlearn: 8.3956833\ttotal: 49.8s\tremaining: 3m 11s\n",
      "3200:\tlearn: 8.3888820\ttotal: 51.3s\tremaining: 3m 9s\n",
      "3300:\tlearn: 8.3821377\ttotal: 53s\tremaining: 3m 7s\n",
      "3400:\tlearn: 8.3754674\ttotal: 54.5s\tremaining: 3m 5s\n",
      "3500:\tlearn: 8.3690340\ttotal: 56.1s\tremaining: 3m 4s\n",
      "3600:\tlearn: 8.3627585\ttotal: 57.6s\tremaining: 3m 2s\n",
      "3700:\tlearn: 8.3555739\ttotal: 59.1s\tremaining: 3m\n",
      "3800:\tlearn: 8.3488814\ttotal: 1m\tremaining: 2m 58s\n",
      "3900:\tlearn: 8.3426749\ttotal: 1m 2s\tremaining: 2m 56s\n",
      "4000:\tlearn: 8.3364560\ttotal: 1m 3s\tremaining: 2m 55s\n",
      "4100:\tlearn: 8.3301469\ttotal: 1m 5s\tremaining: 2m 53s\n",
      "4200:\tlearn: 8.3242336\ttotal: 1m 6s\tremaining: 2m 51s\n",
      "4300:\tlearn: 8.3187400\ttotal: 1m 8s\tremaining: 2m 50s\n",
      "4400:\tlearn: 8.3129209\ttotal: 1m 9s\tremaining: 2m 48s\n",
      "4500:\tlearn: 8.3072009\ttotal: 1m 11s\tremaining: 2m 46s\n",
      "4600:\tlearn: 8.3018455\ttotal: 1m 12s\tremaining: 2m 44s\n",
      "4700:\tlearn: 8.2964051\ttotal: 1m 14s\tremaining: 2m 43s\n",
      "4800:\tlearn: 8.2912839\ttotal: 1m 16s\tremaining: 2m 41s\n",
      "4900:\tlearn: 8.2858830\ttotal: 1m 17s\tremaining: 2m 40s\n",
      "5000:\tlearn: 8.2806005\ttotal: 1m 19s\tremaining: 2m 38s\n",
      "5100:\tlearn: 8.2750960\ttotal: 1m 20s\tremaining: 2m 37s\n",
      "5200:\tlearn: 8.2699798\ttotal: 1m 22s\tremaining: 2m 35s\n",
      "5300:\tlearn: 8.2648712\ttotal: 1m 24s\tremaining: 2m 34s\n",
      "5400:\tlearn: 8.2600091\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "5500:\tlearn: 8.2549422\ttotal: 1m 27s\tremaining: 2m 31s\n",
      "5600:\tlearn: 8.2492396\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "5700:\tlearn: 8.2441517\ttotal: 1m 31s\tremaining: 2m 29s\n",
      "5800:\tlearn: 8.2395592\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "5900:\tlearn: 8.2346912\ttotal: 1m 34s\tremaining: 2m 25s\n",
      "6000:\tlearn: 8.2298100\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "6100:\tlearn: 8.2248049\ttotal: 1m 37s\tremaining: 2m 22s\n",
      "6200:\tlearn: 8.2203336\ttotal: 1m 39s\tremaining: 2m 21s\n",
      "6300:\tlearn: 8.2156113\ttotal: 1m 41s\tremaining: 2m 19s\n",
      "6400:\tlearn: 8.2108159\ttotal: 1m 42s\tremaining: 2m 18s\n",
      "6500:\tlearn: 8.2068046\ttotal: 1m 44s\tremaining: 2m 16s\n",
      "6600:\tlearn: 8.2023290\ttotal: 1m 46s\tremaining: 2m 15s\n",
      "6700:\tlearn: 8.1977519\ttotal: 1m 47s\tremaining: 2m 13s\n",
      "6800:\tlearn: 8.1934420\ttotal: 1m 49s\tremaining: 2m 12s\n",
      "6900:\tlearn: 8.1888638\ttotal: 1m 51s\tremaining: 2m 10s\n",
      "7000:\tlearn: 8.1843506\ttotal: 1m 52s\tremaining: 2m 9s\n",
      "7100:\tlearn: 8.1801153\ttotal: 1m 54s\tremaining: 2m 7s\n",
      "7200:\tlearn: 8.1760612\ttotal: 1m 56s\tremaining: 2m 5s\n",
      "7300:\tlearn: 8.1717318\ttotal: 1m 57s\tremaining: 2m 4s\n",
      "7400:\tlearn: 8.1675013\ttotal: 1m 59s\tremaining: 2m 2s\n",
      "7500:\tlearn: 8.1633551\ttotal: 2m 1s\tremaining: 2m 1s\n",
      "7600:\tlearn: 8.1592519\ttotal: 2m 2s\tremaining: 1m 59s\n",
      "7700:\tlearn: 8.1552732\ttotal: 2m 4s\tremaining: 1m 57s\n",
      "7800:\tlearn: 8.1509256\ttotal: 2m 6s\tremaining: 1m 56s\n",
      "7900:\tlearn: 8.1469139\ttotal: 2m 7s\tremaining: 1m 54s\n",
      "8000:\tlearn: 8.1428172\ttotal: 2m 9s\tremaining: 1m 53s\n",
      "8100:\tlearn: 8.1389766\ttotal: 2m 10s\tremaining: 1m 51s\n",
      "8200:\tlearn: 8.1351061\ttotal: 2m 12s\tremaining: 1m 50s\n",
      "8300:\tlearn: 8.1310902\ttotal: 2m 14s\tremaining: 1m 48s\n",
      "8400:\tlearn: 8.1273763\ttotal: 2m 16s\tremaining: 1m 47s\n",
      "8500:\tlearn: 8.1235496\ttotal: 2m 18s\tremaining: 1m 45s\n",
      "8600:\tlearn: 8.1199202\ttotal: 2m 19s\tremaining: 1m 44s\n",
      "8700:\tlearn: 8.1163583\ttotal: 2m 21s\tremaining: 1m 42s\n",
      "8800:\tlearn: 8.1127272\ttotal: 2m 23s\tremaining: 1m 41s\n",
      "8900:\tlearn: 8.1088466\ttotal: 2m 25s\tremaining: 1m 39s\n",
      "9000:\tlearn: 8.1051563\ttotal: 2m 26s\tremaining: 1m 37s\n",
      "9100:\tlearn: 8.1014970\ttotal: 2m 28s\tremaining: 1m 36s\n",
      "9200:\tlearn: 8.0979848\ttotal: 2m 30s\tremaining: 1m 34s\n",
      "9300:\tlearn: 8.0942946\ttotal: 2m 31s\tremaining: 1m 32s\n",
      "9400:\tlearn: 8.0905582\ttotal: 2m 33s\tremaining: 1m 31s\n",
      "9500:\tlearn: 8.0870328\ttotal: 2m 34s\tremaining: 1m 29s\n",
      "9600:\tlearn: 8.0836963\ttotal: 2m 36s\tremaining: 1m 28s\n",
      "9700:\tlearn: 8.0803390\ttotal: 2m 38s\tremaining: 1m 26s\n",
      "9800:\tlearn: 8.0768505\ttotal: 2m 39s\tremaining: 1m 24s\n",
      "9900:\tlearn: 8.0735356\ttotal: 2m 41s\tremaining: 1m 23s\n",
      "10000:\tlearn: 8.0700703\ttotal: 2m 43s\tremaining: 1m 21s\n",
      "10100:\tlearn: 8.0665144\ttotal: 2m 44s\tremaining: 1m 20s\n",
      "10200:\tlearn: 8.0629744\ttotal: 2m 46s\tremaining: 1m 18s\n",
      "10300:\tlearn: 8.0595198\ttotal: 2m 48s\tremaining: 1m 16s\n",
      "10400:\tlearn: 8.0562082\ttotal: 2m 50s\tremaining: 1m 15s\n",
      "10500:\tlearn: 8.0529743\ttotal: 2m 52s\tremaining: 1m 13s\n",
      "10600:\tlearn: 8.0497751\ttotal: 2m 55s\tremaining: 1m 12s\n",
      "10700:\tlearn: 8.0463073\ttotal: 2m 57s\tremaining: 1m 11s\n",
      "10800:\tlearn: 8.0431710\ttotal: 3m\tremaining: 1m 10s\n",
      "10900:\tlearn: 8.0398027\ttotal: 3m 3s\tremaining: 1m 8s\n",
      "11000:\tlearn: 8.0365197\ttotal: 3m 6s\tremaining: 1m 7s\n",
      "11100:\tlearn: 8.0332934\ttotal: 3m 9s\tremaining: 1m 6s\n",
      "11200:\tlearn: 8.0299966\ttotal: 3m 11s\tremaining: 1m 5s\n",
      "11300:\tlearn: 8.0268408\ttotal: 3m 14s\tremaining: 1m 3s\n",
      "11400:\tlearn: 8.0237365\ttotal: 3m 17s\tremaining: 1m 2s\n",
      "11500:\tlearn: 8.0204282\ttotal: 3m 20s\tremaining: 1m\n",
      "11600:\tlearn: 8.0172370\ttotal: 3m 22s\tremaining: 59.5s\n",
      "11700:\tlearn: 8.0142339\ttotal: 3m 25s\tremaining: 58s\n",
      "11800:\tlearn: 8.0112077\ttotal: 3m 28s\tremaining: 56.6s\n",
      "11900:\tlearn: 8.0081316\ttotal: 3m 31s\tremaining: 55.1s\n",
      "12000:\tlearn: 8.0048987\ttotal: 3m 34s\tremaining: 53.7s\n",
      "12100:\tlearn: 8.0016478\ttotal: 3m 37s\tremaining: 52.1s\n",
      "12200:\tlearn: 7.9985205\ttotal: 3m 40s\tremaining: 50.6s\n",
      "12300:\tlearn: 7.9954233\ttotal: 3m 43s\tremaining: 49s\n",
      "12400:\tlearn: 7.9925193\ttotal: 3m 46s\tremaining: 47.4s\n",
      "12500:\tlearn: 7.9892095\ttotal: 3m 49s\tremaining: 45.8s\n",
      "12600:\tlearn: 7.9861695\ttotal: 3m 51s\tremaining: 44.1s\n",
      "12700:\tlearn: 7.9831942\ttotal: 3m 54s\tremaining: 42.5s\n",
      "12800:\tlearn: 7.9804251\ttotal: 3m 57s\tremaining: 40.8s\n",
      "12900:\tlearn: 7.9776307\ttotal: 4m\tremaining: 39.1s\n",
      "13000:\tlearn: 7.9747490\ttotal: 4m 3s\tremaining: 37.4s\n",
      "13100:\tlearn: 7.9719694\ttotal: 4m 5s\tremaining: 35.6s\n",
      "13200:\tlearn: 7.9690727\ttotal: 4m 8s\tremaining: 33.9s\n",
      "13300:\tlearn: 7.9662544\ttotal: 4m 11s\tremaining: 32.1s\n",
      "13400:\tlearn: 7.9632890\ttotal: 4m 14s\tremaining: 30.4s\n",
      "13500:\tlearn: 7.9604760\ttotal: 4m 17s\tremaining: 28.6s\n",
      "13600:\tlearn: 7.9577996\ttotal: 4m 20s\tremaining: 26.7s\n",
      "13700:\tlearn: 7.9549430\ttotal: 4m 22s\tremaining: 24.9s\n",
      "13800:\tlearn: 7.9520066\ttotal: 4m 25s\tremaining: 23.1s\n",
      "13900:\tlearn: 7.9490570\ttotal: 4m 28s\tremaining: 21.2s\n",
      "14000:\tlearn: 7.9460004\ttotal: 4m 31s\tremaining: 19.4s\n",
      "14100:\tlearn: 7.9429187\ttotal: 4m 34s\tremaining: 17.5s\n",
      "14200:\tlearn: 7.9400807\ttotal: 4m 37s\tremaining: 15.6s\n",
      "14300:\tlearn: 7.9373723\ttotal: 4m 40s\tremaining: 13.7s\n",
      "14400:\tlearn: 7.9345806\ttotal: 4m 42s\tremaining: 11.8s\n",
      "14500:\tlearn: 7.9318313\ttotal: 4m 45s\tremaining: 9.83s\n",
      "14600:\tlearn: 7.9291213\ttotal: 4m 48s\tremaining: 7.88s\n",
      "14700:\tlearn: 7.9264142\ttotal: 4m 51s\tremaining: 5.92s\n",
      "14800:\tlearn: 7.9235285\ttotal: 4m 54s\tremaining: 3.95s\n",
      "14900:\tlearn: 7.9208547\ttotal: 4m 56s\tremaining: 1.97s\n",
      "14999:\tlearn: 7.9181492\ttotal: 4m 59s\tremaining: 0us\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4400\n",
      "[LightGBM] [Info] Number of data points in the train set: 734002, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -0.088886\n",
      "RMSE: 7.925799531795108\n",
      "MAE: 5.351087785097162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "catboost_reg = CatBoostRegressor(iterations=15000, learning_rate=0.1, depth=3, verbose=100, early_stopping_rounds=100)\n",
    "catboost_reg.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "lgbm_reg = LGBMRegressor(n_estimators=5000, learning_rate=0.1)\n",
    "lgbm_reg.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='l1',\n",
    ")\n",
    "\n",
    "ensemble_reg = VotingRegressor(estimators=[\n",
    "    ('catboost', catboost_reg),\n",
    "    ('lightgbm', lgbm_reg)\n",
    "])\n",
    "\n",
    "ensemble_reg.fit(X_train, y_train)\n",
    "y_pred = ensemble_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
